{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cbdef372ad24474289dcfa8a470fe4bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92d6738ec36b41a7885e52fdce8b4a1d","IPY_MODEL_bfc2292a75364055bac3e4f9120653ee","IPY_MODEL_a852be45a58a468e8f8bb9a05ce733c0"],"layout":"IPY_MODEL_22c493c0ce694c7585dcca8bd8339c75"}},"92d6738ec36b41a7885e52fdce8b4a1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01e5d284552743e69b252a6a8733d0ad","placeholder":"​","style":"IPY_MODEL_9f4fdb830f5e4a72a2e29f98cebea076","value":"model.safetensors: 100%"}},"bfc2292a75364055bac3e4f9120653ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c228035ce727492cb2765fbdf250491c","max":2355738764,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f75b928f21474b0f9b493940262b51b4","value":2355738764}},"a852be45a58a468e8f8bb9a05ce733c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82fd8f1a0d5841b299c0b245fb180c6f","placeholder":"​","style":"IPY_MODEL_433b4c8eaa764cfea0709d673730c1ee","value":" 2.36G/2.36G [00:24&lt;00:00, 82.4MB/s]"}},"22c493c0ce694c7585dcca8bd8339c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01e5d284552743e69b252a6a8733d0ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f4fdb830f5e4a72a2e29f98cebea076":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c228035ce727492cb2765fbdf250491c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f75b928f21474b0f9b493940262b51b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82fd8f1a0d5841b299c0b245fb180c6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"433b4c8eaa764cfea0709d673730c1ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f4bb15113d14dcd9bea2ba7ca36a366":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_673dfabff1d04b3ba08a005aede97c4e","IPY_MODEL_0b030434a1ac4cf581fd26f7af93e8a3","IPY_MODEL_c9299a5cab774ce4bb6d227a8656b9be"],"layout":"IPY_MODEL_5d048010182d4d4f93cd59156cc8cbf7"}},"673dfabff1d04b3ba08a005aede97c4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4f862f250be403ea021c271efa1aeb9","placeholder":"​","style":"IPY_MODEL_4e1203b997a4496e913ecc63b2a9a66b","value":"generation_config.json: 100%"}},"0b030434a1ac4cf581fd26f7af93e8a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a8138489a594bd79511e56e53b4c5f8","max":271,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ca02ca3a3bf4d7d991bfb2b35102913","value":271}},"c9299a5cab774ce4bb6d227a8656b9be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bc50c123245467497fd987c0d9119b6","placeholder":"​","style":"IPY_MODEL_96f51b0add114ad3954e1bd793eff882","value":" 271/271 [00:00&lt;00:00, 19.1kB/s]"}},"5d048010182d4d4f93cd59156cc8cbf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4f862f250be403ea021c271efa1aeb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1203b997a4496e913ecc63b2a9a66b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a8138489a594bd79511e56e53b4c5f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ca02ca3a3bf4d7d991bfb2b35102913":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9bc50c123245467497fd987c0d9119b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96f51b0add114ad3954e1bd793eff882":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8173f3fde9144abf9bf0c3e58a311939":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63bbb3370ec34d6fb59d428b205109c7","IPY_MODEL_db222feafc524bbe940daab9036dc7ed","IPY_MODEL_90cf566a44ff4bc19589aa9b5750f77a"],"layout":"IPY_MODEL_3d067fbd439741da8dfd0e25b1950b66"}},"63bbb3370ec34d6fb59d428b205109c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcf11701254849f687521a311476b579","placeholder":"​","style":"IPY_MODEL_440f70e2ef3b44708602bb36daf1d901","value":"tokenizer_config.json: "}},"db222feafc524bbe940daab9036dc7ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77596287098e42d7bb7a81556a698984","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95ed98d244334844bb9b72e07904e277","value":1}},"90cf566a44ff4bc19589aa9b5750f77a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f3fc5437bdc4cd3ad7a77c479706563","placeholder":"​","style":"IPY_MODEL_8e6aab692f544dc3bbd74be766b72ed9","value":" 7.36k/? [00:00&lt;00:00, 461kB/s]"}},"3d067fbd439741da8dfd0e25b1950b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcf11701254849f687521a311476b579":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"440f70e2ef3b44708602bb36daf1d901":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77596287098e42d7bb7a81556a698984":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"95ed98d244334844bb9b72e07904e277":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f3fc5437bdc4cd3ad7a77c479706563":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e6aab692f544dc3bbd74be766b72ed9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4873e9a7f424a2ab5af9050c9b8f508":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b94256535e77494999d124197d82ae83","IPY_MODEL_b63e0d3563de43c0adcab769441df5c0","IPY_MODEL_880cad0888064c89b4e3c1aad4e7f1b0"],"layout":"IPY_MODEL_186df51d61dd4c159bc0ee9588cc60d9"}},"b94256535e77494999d124197d82ae83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7db325d1c33740dbb940e856191b33a4","placeholder":"​","style":"IPY_MODEL_bdd07c34ca524baf932ecd7df6fd8401","value":"vocab.json: "}},"b63e0d3563de43c0adcab769441df5c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8db3630b69f548f08c2ebdc67582d2d1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6369967617e04c1fa8f5b6fd0e55eba5","value":1}},"880cad0888064c89b4e3c1aad4e7f1b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad948b5aaaa6460daa2770893b066b0c","placeholder":"​","style":"IPY_MODEL_b2d3506d4cf247fbb9042e204de73d97","value":" 2.78M/? [00:00&lt;00:00, 60.0MB/s]"}},"186df51d61dd4c159bc0ee9588cc60d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7db325d1c33740dbb940e856191b33a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdd07c34ca524baf932ecd7df6fd8401":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8db3630b69f548f08c2ebdc67582d2d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"6369967617e04c1fa8f5b6fd0e55eba5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad948b5aaaa6460daa2770893b066b0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2d3506d4cf247fbb9042e204de73d97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fb0e3fa2d7d4c15947a9ac3b9bee54f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2eec1131d2ae4f129e76b9395756167e","IPY_MODEL_0ae5296777a34a37a2774ae406bbe959","IPY_MODEL_2a029e384a3f4958991e86a55f1c00ae"],"layout":"IPY_MODEL_f2190dc579f54b1b9d9eb2aeb89515f8"}},"2eec1131d2ae4f129e76b9395756167e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06514b4c00914a15b684e3d5e83ce7e2","placeholder":"​","style":"IPY_MODEL_83fe1eafb6904179b5a51b1a4c848edc","value":"merges.txt: "}},"0ae5296777a34a37a2774ae406bbe959":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_903b078a16084b03b4f8a1f7d2707663","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9255eff93fc4e40867608d0f3e3483f","value":1}},"2a029e384a3f4958991e86a55f1c00ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_503bab7b31bd454aaa9a6ed8277ace06","placeholder":"​","style":"IPY_MODEL_3083f79d935b4644b755842d1e7f3805","value":" 1.67M/? [00:00&lt;00:00, 49.8MB/s]"}},"f2190dc579f54b1b9d9eb2aeb89515f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06514b4c00914a15b684e3d5e83ce7e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83fe1eafb6904179b5a51b1a4c848edc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"903b078a16084b03b4f8a1f7d2707663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d9255eff93fc4e40867608d0f3e3483f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"503bab7b31bd454aaa9a6ed8277ace06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3083f79d935b4644b755842d1e7f3805":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6574f869173849d5aa3dbf00db3d7650":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b90921ebe44482c9aa1acdfc8ff97fa","IPY_MODEL_7144dcfe79bb46418087986354fbfae2","IPY_MODEL_e5a0f602a1a948cf85997c5b132d5080"],"layout":"IPY_MODEL_ac79b9429949486ab47159287012786d"}},"2b90921ebe44482c9aa1acdfc8ff97fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cc5afa58f264c00927c53fdc0faa111","placeholder":"​","style":"IPY_MODEL_02d270131d9c4f1ab90ded6c551ba5b0","value":"added_tokens.json: 100%"}},"7144dcfe79bb46418087986354fbfae2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad24f5d774334326a50aa84c20e92e17","max":605,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9bc369a29b1a4b71b6ca6e32784b6f4f","value":605}},"e5a0f602a1a948cf85997c5b132d5080":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8c665108bbc496e9ed5f48fff8c9d85","placeholder":"​","style":"IPY_MODEL_4765d53c9719423d90ee45b78a731e5f","value":" 605/605 [00:00&lt;00:00, 62.1kB/s]"}},"ac79b9429949486ab47159287012786d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cc5afa58f264c00927c53fdc0faa111":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02d270131d9c4f1ab90ded6c551ba5b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad24f5d774334326a50aa84c20e92e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bc369a29b1a4b71b6ca6e32784b6f4f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8c665108bbc496e9ed5f48fff8c9d85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4765d53c9719423d90ee45b78a731e5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c276658861a4769b9361b0e7b3478e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22f2b65d7fe644139f6b92f0d8ce10a6","IPY_MODEL_4c06e8e072c14d4f836727571f162484","IPY_MODEL_a2e41a30421f439292d0805533e2db1c"],"layout":"IPY_MODEL_d695605128b740ef8e6431d7fdd57f11"}},"22f2b65d7fe644139f6b92f0d8ce10a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ea23464c8ae4be3970b5832a6d99b8c","placeholder":"​","style":"IPY_MODEL_fdd4b917b3cf491595d931fc44d90c12","value":"special_tokens_map.json: 100%"}},"4c06e8e072c14d4f836727571f162484":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f211003ef234a8eae434a3b63ff8e88","max":614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc2217bf400f444d97ebcaac0d58f61b","value":614}},"a2e41a30421f439292d0805533e2db1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1ec5c8d68e845f29248913277c5e721","placeholder":"​","style":"IPY_MODEL_b0713f71f6c44807b692495b18f0b0e3","value":" 614/614 [00:00&lt;00:00, 72.2kB/s]"}},"d695605128b740ef8e6431d7fdd57f11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ea23464c8ae4be3970b5832a6d99b8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdd4b917b3cf491595d931fc44d90c12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f211003ef234a8eae434a3b63ff8e88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc2217bf400f444d97ebcaac0d58f61b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1ec5c8d68e845f29248913277c5e721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0713f71f6c44807b692495b18f0b0e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beb37839cae7430e9c02ac4d6f4bfe98":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70b01509a6964a5b97c6260e9d2e01ad","IPY_MODEL_f86bcf54613e4061870b8b1466b00cd8","IPY_MODEL_a86b6eda62824b2591d3f9dc48ac5588"],"layout":"IPY_MODEL_c69266e2aaf448f49b99183ac413150f"}},"70b01509a6964a5b97c6260e9d2e01ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_624cba9ef9fa4d37961c80107c4b1f8a","placeholder":"​","style":"IPY_MODEL_e483347ea4ff49c0aac7e8ba794c124e","value":"tokenizer.json: 100%"}},"f86bcf54613e4061870b8b1466b00cd8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a33420bd8f8540f8aac30d737811f15c","max":11421896,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf934741815a40ef9880e5711016a63c","value":11421896}},"a86b6eda62824b2591d3f9dc48ac5588":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f152f31d5e21414493e9c0b06a03cc0b","placeholder":"​","style":"IPY_MODEL_7089e87829654986a3932288c71c3672","value":" 11.4M/11.4M [00:00&lt;00:00, 68.1kB/s]"}},"c69266e2aaf448f49b99183ac413150f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"624cba9ef9fa4d37961c80107c4b1f8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e483347ea4ff49c0aac7e8ba794c124e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a33420bd8f8540f8aac30d737811f15c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf934741815a40ef9880e5711016a63c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f152f31d5e21414493e9c0b06a03cc0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7089e87829654986a3932288c71c3672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install unsloth  trl","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39qfhaXY-qja","outputId":"95aa144b-ca1d-455e-927d-1d5efb943b72","trusted":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-09-18T14:49:10.425571Z","iopub.execute_input":"2025-09-18T14:49:10.425744Z","iopub.status.idle":"2025-09-18T14:53:48.778311Z","shell.execute_reply.started":"2025-09-18T14:49:10.425728Z","shell.execute_reply":"2025-09-18T14:53:48.777341Z"},"collapsed":true},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.9.6-py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting trl\n  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\nCollecting unsloth_zoo>=2025.9.7 (from unsloth)\n  Downloading unsloth_zoo-2025.9.8-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.52.4)\nRequirement already satisfied: datasets<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.8.1)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.15.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\nCollecting huggingface_hub>=0.34.0 (from unsloth)\n  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\nINFO: pip is looking at multiple versions of trl to determine which version is compatible with other requirements. This could take a while.\nCollecting trl\n  Downloading trl-0.22.2-py3-none-any.whl.metadata (11 kB)\nCollecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3 (from unsloth)\n  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth) (0.21.2)\nRequirement already satisfied: torchao in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.7->unsloth) (0.10.0)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.9.7->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.7->unsloth) (11.2.1)\nCollecting msgspec (from unsloth_zoo>=2025.9.7->unsloth)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.0.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.9.6-py3-none-any.whl (312 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.6/312.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading trl-0.22.2-py3-none-any.whl (544 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.4/563.4 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.9.8-py3-none-any.whl (230 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.2/230.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m140.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface_hub, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.33.1\n    Uninstalling huggingface-hub-0.33.1:\n      Successfully uninstalled huggingface-hub-0.33.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 fsspec-2025.3.0 huggingface_hub-0.35.0 msgspec-0.19.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 shtab-1.7.2 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 transformers-4.55.4 triton-3.4.0 trl-0.22.2 tyro-0.9.31 unsloth-2025.9.6 unsloth_zoo-2025.9.8 xformers-0.0.32.post2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/domager73/base.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:55:04.490812Z","iopub.execute_input":"2025-09-18T14:55:04.491554Z","iopub.status.idle":"2025-09-18T14:55:04.662513Z","shell.execute_reply.started":"2025-09-18T14:55:04.491528Z","shell.execute_reply":"2025-09-18T14:55:04.661535Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'base' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/base')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:55:04.837512Z","iopub.execute_input":"2025-09-18T14:55:04.837834Z","iopub.status.idle":"2025-09-18T14:55:04.842303Z","shell.execute_reply.started":"2025-09-18T14:55:04.837805Z","shell.execute_reply":"2025-09-18T14:55:04.841506Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import IterableDataset, Dataset\nfrom datasets import Dataset as HFDataset\nimport random\nfrom typing import Optional, List\nimport numpy as np\nfrom transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM\nfrom trl import GRPOConfig, GRPOTrainer\nimport matplotlib.pyplot as plt\nimport json\nfrom huggingface_hub import HfApi\nfrom point_set import PointSet\nfrom tqdm import tqdm","metadata":{"id":"FECUyhD-0eSy","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:55:05.316771Z","iopub.execute_input":"2025-09-18T14:55:05.317096Z","iopub.status.idle":"2025-09-18T14:55:05.322500Z","shell.execute_reply.started":"2025-09-18T14:55:05.317072Z","shell.execute_reply":"2025-09-18T14:55:05.321705Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class PointSetIterableDataset(IterableDataset):\n    def __init__(self, game, num_samples=1000, difficulty=None):\n        self.game = game\n        self.num_samples = num_samples\n        self.difficulty = difficulty\n\n    def __iter__(self):\n        for _ in range(self.num_samples):\n            game_data_list = self.game.generate(\n                num_of_questions=1,\n                difficulty=self.difficulty if self.difficulty else random.randint(1, 10)\n            )\n\n            if game_data_list:\n                data = game_data_list[0]\n                yield {\n                    \"question\": data.question,\n                    \"answer\": data.answer,\n                    \"difficulty\": data.difficulty,\n                    \"metadata\": data.metadata\n                }","metadata":{"id":"T6QEy8zY2syM","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:55:14.392713Z","iopub.execute_input":"2025-09-18T14:55:14.393564Z","iopub.status.idle":"2025-09-18T14:55:14.398478Z","shell.execute_reply.started":"2025-09-18T14:55:14.393535Z","shell.execute_reply":"2025-09-18T14:55:14.397811Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def create_test_datasets(game, difficulties=[1, 3, 5, 7, 10], samples_per_difficulty=100):\n    test_datasets = {}\n\n    for difficulty in difficulties:\n        print(f\"Creating test dataset for difficulty {difficulty}...\")\n        game_data_list = game.generate(\n            num_of_questions=samples_per_difficulty,\n            difficulty=difficulty\n        )\n\n        dataset_data = []\n        for data in game_data_list:\n            dataset_data.append({\n                \"question\": data.question,\n                \"answer\": data.answer,\n                \"difficulty\": data.difficulty,\n                \"metadata\": data.metadata\n            })\n\n        test_datasets[f\"difficulty_{difficulty}\"] = HFDataset.from_list(dataset_data)\n\n    return test_datasets\n\n\ndef format_prompt(question):\n    return f\"\"\"<|im_start|>system\n{SYSTEM_PROMPT}<|im_end|>\n<|im_start|>user\n{question}<|im_end|>\n<|im_start|>assistant\n\"\"\"\n\n\ndef correctness_reward_func(game, examples, predictions, **kwargs):\n    rewards = []\n    for i, (example, prediction) in enumerate(zip(examples, predictions)):\n        data = type('Data', (), {\n            'question': example['question'],\n            'answer': example['answer'],\n            'difficulty': example['difficulty'],\n            'metadata': example['metadata']\n        })()\n\n        is_correct = game.verify(data, prediction)\n        rewards.append(1.0 if is_correct else 0)\n\n    return rewards","metadata":{"id":"qiYVhMw72v4P","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:55:16.354118Z","iopub.execute_input":"2025-09-18T14:55:16.354407Z","iopub.status.idle":"2025-09-18T14:55:16.361265Z","shell.execute_reply.started":"2025-09-18T14:55:16.354386Z","shell.execute_reply":"2025-09-18T14:55:16.360660Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"id":"OYpOa_L0zCIW","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:55:18.939179Z","iopub.execute_input":"2025-09-18T14:55:18.939467Z","iopub.status.idle":"2025-09-18T14:55:18.943200Z","shell.execute_reply.started":"2025-09-18T14:55:18.939446Z","shell.execute_reply":"2025-09-18T14:55:18.942553Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import unsloth\nfrom unsloth import FastLanguageModel\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom trl import GRPOConfig, GRPOTrainer\nfrom point_set import PointSet\nfrom point_set_verifier import PointSetVerifier\nimport torch\n\nclass PointSetGRPODataset(torch.utils.data.Dataset):\n    def __init__(self, game, num_samples=5000, difficulties=[1, 3, 5, 7, 10]):\n        self.game = game\n        self.num_samples = num_samples\n        self.data = []\n\n\n        for i in tqdm(difficulties):\n          for _ in range(num_samples):\n              data_point = game.generate(num_of_questions=1,difficulty = i)\n              prompt = format_prompt(data_point[0].question)\n              self.data.append({\n                  \"prompt\": prompt,\n                  \"question\": data_point[0].question,\n                  \"answer\": data_point[0].answer,\n                  \"difficulty\": data_point[0].difficulty,\n                  \"metadata\": data_point[0].metadata\n              })\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n\ndef preprocess_function(examples, tokenizer):\n    model_inputs = tokenizer(\n        examples[\"prompt\"],\n        max_length=1024,\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\",\n    )\n\n    return model_inputs\n\ndef format_prompt(question):\n    SYSTEM_PROMPT = \"\"\"You are an expert in point set topology. Answer ONLY with one word: 'internal', 'boundary', or 'external'. Do not include any other text, explanations, or formatting.\"\"\"\n    return f\"\"\"<|im_start|>system\n{SYSTEM_PROMPT}<|im_end|>\n<|im_start|>user\n{question}<|im_end|>\n<|im_start|>assistant\n\"\"\"\n\n\ngame = PointSet()\n\nprint('Genering train data')\ntrain_dataset = PointSetGRPODataset(game, num_samples=1200, difficulties = [3])\nprint('Genering test data')\ntest_datasets = create_test_datasets(game,difficulties=[3])\n\nmodel_name = \"Qwen/Qwen2.5-3B-Instruct\"\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = model_name,\n    max_seq_length = 1024,\n    dtype = None,\n    load_in_4bit = True,\n)\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 8,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    lora_alpha = 8,\n    lora_dropout = 0,\n    bias = \"none\",\n    use_gradient_checkpointing = True,\n    random_state = 3407,\n    use_rslora = False,\n    loftq_config = None,\n)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:57:37.144780Z","iopub.execute_input":"2025-09-18T14:57:37.145566Z","iopub.status.idle":"2025-09-18T14:58:00.218047Z","shell.execute_reply.started":"2025-09-18T14:57:37.145539Z","shell.execute_reply":"2025-09-18T14:58:00.217216Z"}},"outputs":[{"name":"stdout","text":"Genering train data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Genering test data\nCreating test dataset for difficulty 3...\n==((====))==  Unsloth 2025.9.6: Fast Qwen2 patching. Transformers: 4.55.4.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.36G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"460bb868abcc4916bfe8764219226957"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bac866f88a3549939ea5293e0e9ba591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ef5ce2aab1144638c94f277ed48777a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea0f2b3327d5431da5cd408159dc1ab2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"558db7c49dea4a8c98da442b93fe4f1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45d5141b60384e7baf8ac69c07ee7c64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf16c402581e4a3596a7951af366daa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09794290b60f4bb68a0f222a30ae123c"}},"metadata":{}},{"name":"stderr","text":"Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\nare not enabled or a bias term (like in Qwen) is used.\nUnsloth 2025.9.6 patched 36 layers with 36 QKV layers, 36 O layers and 0 MLP layers.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"training_args = GRPOConfig(\n    output_dir=\"./point_set_agent\",\n    per_device_train_batch_size=3,\n    gradient_accumulation_steps=8,\n    learning_rate=1e-5,\n    optim=\"adamw_torch\",\n    max_steps=100,\n    logging_steps=1,\n    save_steps=50,\n    eval_steps=25,\n    warmup_steps=10,\n    fp16=True,\n    report_to=\"none\",\n    remove_unused_columns=False,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":939,"referenced_widgets":["cbdef372ad24474289dcfa8a470fe4bc","92d6738ec36b41a7885e52fdce8b4a1d","bfc2292a75364055bac3e4f9120653ee","a852be45a58a468e8f8bb9a05ce733c0","22c493c0ce694c7585dcca8bd8339c75","01e5d284552743e69b252a6a8733d0ad","9f4fdb830f5e4a72a2e29f98cebea076","c228035ce727492cb2765fbdf250491c","f75b928f21474b0f9b493940262b51b4","82fd8f1a0d5841b299c0b245fb180c6f","433b4c8eaa764cfea0709d673730c1ee","6f4bb15113d14dcd9bea2ba7ca36a366","673dfabff1d04b3ba08a005aede97c4e","0b030434a1ac4cf581fd26f7af93e8a3","c9299a5cab774ce4bb6d227a8656b9be","5d048010182d4d4f93cd59156cc8cbf7","c4f862f250be403ea021c271efa1aeb9","4e1203b997a4496e913ecc63b2a9a66b","1a8138489a594bd79511e56e53b4c5f8","5ca02ca3a3bf4d7d991bfb2b35102913","9bc50c123245467497fd987c0d9119b6","96f51b0add114ad3954e1bd793eff882","8173f3fde9144abf9bf0c3e58a311939","63bbb3370ec34d6fb59d428b205109c7","db222feafc524bbe940daab9036dc7ed","90cf566a44ff4bc19589aa9b5750f77a","3d067fbd439741da8dfd0e25b1950b66","dcf11701254849f687521a311476b579","440f70e2ef3b44708602bb36daf1d901","77596287098e42d7bb7a81556a698984","95ed98d244334844bb9b72e07904e277","9f3fc5437bdc4cd3ad7a77c479706563","8e6aab692f544dc3bbd74be766b72ed9","c4873e9a7f424a2ab5af9050c9b8f508","b94256535e77494999d124197d82ae83","b63e0d3563de43c0adcab769441df5c0","880cad0888064c89b4e3c1aad4e7f1b0","186df51d61dd4c159bc0ee9588cc60d9","7db325d1c33740dbb940e856191b33a4","bdd07c34ca524baf932ecd7df6fd8401","8db3630b69f548f08c2ebdc67582d2d1","6369967617e04c1fa8f5b6fd0e55eba5","ad948b5aaaa6460daa2770893b066b0c","b2d3506d4cf247fbb9042e204de73d97","5fb0e3fa2d7d4c15947a9ac3b9bee54f","2eec1131d2ae4f129e76b9395756167e","0ae5296777a34a37a2774ae406bbe959","2a029e384a3f4958991e86a55f1c00ae","f2190dc579f54b1b9d9eb2aeb89515f8","06514b4c00914a15b684e3d5e83ce7e2","83fe1eafb6904179b5a51b1a4c848edc","903b078a16084b03b4f8a1f7d2707663","d9255eff93fc4e40867608d0f3e3483f","503bab7b31bd454aaa9a6ed8277ace06","3083f79d935b4644b755842d1e7f3805","6574f869173849d5aa3dbf00db3d7650","2b90921ebe44482c9aa1acdfc8ff97fa","7144dcfe79bb46418087986354fbfae2","e5a0f602a1a948cf85997c5b132d5080","ac79b9429949486ab47159287012786d","5cc5afa58f264c00927c53fdc0faa111","02d270131d9c4f1ab90ded6c551ba5b0","ad24f5d774334326a50aa84c20e92e17","9bc369a29b1a4b71b6ca6e32784b6f4f","e8c665108bbc496e9ed5f48fff8c9d85","4765d53c9719423d90ee45b78a731e5f","7c276658861a4769b9361b0e7b3478e4","22f2b65d7fe644139f6b92f0d8ce10a6","4c06e8e072c14d4f836727571f162484","a2e41a30421f439292d0805533e2db1c","d695605128b740ef8e6431d7fdd57f11","6ea23464c8ae4be3970b5832a6d99b8c","fdd4b917b3cf491595d931fc44d90c12","5f211003ef234a8eae434a3b63ff8e88","bc2217bf400f444d97ebcaac0d58f61b","e1ec5c8d68e845f29248913277c5e721","b0713f71f6c44807b692495b18f0b0e3","beb37839cae7430e9c02ac4d6f4bfe98","70b01509a6964a5b97c6260e9d2e01ad","f86bcf54613e4061870b8b1466b00cd8","a86b6eda62824b2591d3f9dc48ac5588","c69266e2aaf448f49b99183ac413150f","624cba9ef9fa4d37961c80107c4b1f8a","e483347ea4ff49c0aac7e8ba794c124e","a33420bd8f8540f8aac30d737811f15c","cf934741815a40ef9880e5711016a63c","f152f31d5e21414493e9c0b06a03cc0b","7089e87829654986a3932288c71c3672"]},"id":"2M6ewBbk20qP","outputId":"361e5c69-c797-4e91-8c27-111202fab1a6","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:59:50.980727Z","iopub.execute_input":"2025-09-18T14:59:50.981065Z","iopub.status.idle":"2025-09-18T14:59:51.014856Z","shell.execute_reply.started":"2025-09-18T14:59:50.981042Z","shell.execute_reply":"2025-09-18T14:59:51.014283Z"}},"outputs":[{"name":"stdout","text":"Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\nWe will change the batch size of 3 to the `num_generations` of 8\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n\nlog_file =  f\"training_log.json\"\ndef grpo_reward_func(prompts, completions, **kwargs):\n    rewards = []\n    verifier = PointSetVerifier()\n\n    step_logs = []\n\n    prompt_to_data = {}\n    for item in train_dataset.data:\n        prompt_to_data[item[\"prompt\"]] = item\n\n    for i, (prompt, completion) in enumerate(zip(prompts, completions)):\n        if prompt in prompt_to_data:\n            data_item = prompt_to_data[prompt]\n\n            class Data:\n                def __init__(self, question, answer, difficulty, metadata):\n                    self.question = question\n                    self.answer = answer\n                    self.difficulty = difficulty\n                    self.metadata = metadata\n\n            data = Data(\n                question=data_item['question'],\n                answer=data_item['answer'],\n                difficulty=data_item['difficulty'],\n                metadata=data_item['metadata']\n            )\n\n            is_correct = verifier.verify(data, completion)\n            reward = 1.0 if is_correct else 0\n            rewards.append(reward)\n\n            step_log = {\n                \"completion\": completion,\n                \"expected_answer\": data_item['answer'],\n                \"is_correct\": is_correct,\n                \"reward\": float(reward),\n                \"difficulty\": data_item['difficulty'],\n                \"question\": data_item['question'],\n                \"answer\": data_item['answer'],\n            }\n            step_logs.append(step_log)\n\n        else:\n            rewards.append(0.0)\n            step_log = {\n                \"completion\": completion,\n                \"error\": \"prompt_not_found_in_dataset\",\n                \"reward\": 0.0\n            }\n            step_logs.append(step_log)\n\n    with open(log_file, 'a', encoding='utf-8') as f:\n        for log_entry in step_logs:\n            f.write(json.dumps(log_entry, ensure_ascii=False) + '\\n')\n\n    return torch.tensor(rewards, dtype=torch.float32)\n\ntrainer = GRPOTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    reward_funcs=[grpo_reward_func],\n    preprocess_logits_for_metrics=lambda logits, labels: logits.argmax(dim=-1),\n)\n\nprint(\"Starting training...\")\ntrainer.train()\nprint(\"Training completed successfully!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"fc0ry8jzgzS3","outputId":"2d7590d1-1b3d-4242-ff9d-7a7a553e5f13","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:59:54.224575Z","iopub.execute_input":"2025-09-18T14:59:54.224823Z","iopub.status.idle":"2025-09-18T15:18:36.716375Z","shell.execute_reply.started":"2025-09-18T14:59:54.224807Z","shell.execute_reply":"2025-09-18T15:18:36.715353Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,200 | Num Epochs = 2 | Total steps = 100\nO^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 8 x 1) = 128\n \"-____-\"     Trainable parameters = 3,686,400 of 3,089,625,088 (0.12% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='22' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 22/100 16:50 < 1:05:41, 0.02 it/s, Epoch 0.28/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>reward</th>\n      <th>reward_std</th>\n      <th>completions / mean_length</th>\n      <th>completions / min_length</th>\n      <th>completions / max_length</th>\n      <th>completions / clipped_ratio</th>\n      <th>completions / mean_terminated_length</th>\n      <th>completions / min_terminated_length</th>\n      <th>completions / max_terminated_length</th>\n      <th>kl</th>\n      <th>rewards / grpo_reward_func / mean</th>\n      <th>rewards / grpo_reward_func / std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.210938</td>\n      <td>0.212007</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000047</td>\n      <td>0.210938</td>\n      <td>0.409577</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.203125</td>\n      <td>0.197276</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000038</td>\n      <td>0.203125</td>\n      <td>0.403906</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000000</td>\n      <td>0.304688</td>\n      <td>0.252244</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000056</td>\n      <td>0.304688</td>\n      <td>0.462084</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000000</td>\n      <td>0.429688</td>\n      <td>0.255145</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000042</td>\n      <td>0.429688</td>\n      <td>0.496977</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000000</td>\n      <td>0.210938</td>\n      <td>0.317484</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000045</td>\n      <td>0.210938</td>\n      <td>0.409577</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.000000</td>\n      <td>0.289062</td>\n      <td>0.373746</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000020</td>\n      <td>0.289062</td>\n      <td>0.455108</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.000000</td>\n      <td>0.265625</td>\n      <td>0.342455</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000038</td>\n      <td>0.265625</td>\n      <td>0.443401</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n      <td>0.241999</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000034</td>\n      <td>0.250000</td>\n      <td>0.434714</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000000</td>\n      <td>0.328125</td>\n      <td>0.317479</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000031</td>\n      <td>0.328125</td>\n      <td>0.471376</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000000</td>\n      <td>0.281250</td>\n      <td>0.394545</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000149</td>\n      <td>0.281250</td>\n      <td>0.451376</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.000000</td>\n      <td>0.359375</td>\n      <td>0.420057</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000327</td>\n      <td>0.359375</td>\n      <td>0.481703</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.000000</td>\n      <td>0.296875</td>\n      <td>0.407148</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000367</td>\n      <td>0.296875</td>\n      <td>0.458676</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.000000</td>\n      <td>0.390625</td>\n      <td>0.353241</td>\n      <td>2.703125</td>\n      <td>2.000000</td>\n      <td>92.000000</td>\n      <td>0.000000</td>\n      <td>2.703125</td>\n      <td>2.000000</td>\n      <td>92.000000</td>\n      <td>0.002690</td>\n      <td>0.390625</td>\n      <td>0.489808</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.000000</td>\n      <td>0.476562</td>\n      <td>0.438207</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.001357</td>\n      <td>0.476562</td>\n      <td>0.501413</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.000000</td>\n      <td>0.281250</td>\n      <td>0.250127</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.001418</td>\n      <td>0.281250</td>\n      <td>0.451376</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.000000</td>\n      <td>0.351562</td>\n      <td>0.362430</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.002392</td>\n      <td>0.351562</td>\n      <td>0.479334</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.000000</td>\n      <td>0.406250</td>\n      <td>0.248829</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.003131</td>\n      <td>0.406250</td>\n      <td>0.493062</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.000000</td>\n      <td>0.351562</td>\n      <td>0.283298</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.005487</td>\n      <td>0.351562</td>\n      <td>0.479334</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.000000</td>\n      <td>0.296875</td>\n      <td>0.356124</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.005854</td>\n      <td>0.296875</td>\n      <td>0.458676</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.000100</td>\n      <td>0.265625</td>\n      <td>0.395843</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.009440</td>\n      <td>0.265625</td>\n      <td>0.443401</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1106909462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2547\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"trainer.state.log_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T18:31:30.835740Z","iopub.execute_input":"2025-09-15T18:31:30.835990Z","iopub.status.idle":"2025-09-15T18:31:30.863624Z","shell.execute_reply.started":"2025-09-15T18:31:30.835974Z","shell.execute_reply":"2025-09-15T18:31:30.862801Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'loss': 0.0,\n  'grad_norm': nan,\n  'learning_rate': 0.0,\n  'num_tokens': 21920.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3203125,\n  'rewards/grpo_reward_func/std': 0.4684300124645233,\n  'reward': 0.3203125,\n  'reward_std': 0.36273446679115295,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.0,\n  'epoch': 0.013333333333333334,\n  'step': 1},\n {'loss': -0.0,\n  'grad_norm': nan,\n  'learning_rate': 0.0,\n  'num_tokens': 45360.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.34375,\n  'rewards/grpo_reward_func/std': 0.47682511806488037,\n  'reward': 0.34375,\n  'reward_std': 0.4371459484100342,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.0,\n  'epoch': 0.02666666666666667,\n  'step': 2},\n {'loss': 0.0,\n  'grad_norm': nan,\n  'learning_rate': 0.0,\n  'num_tokens': 68528.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.7109375,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.7109375,\n  'reward_std': 0.30327799916267395,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.0,\n  'epoch': 0.04,\n  'step': 3},\n {'loss': -0.0,\n  'grad_norm': 9.206863403320312,\n  'learning_rate': 0.0,\n  'num_tokens': 90768.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.1796875,\n  'rewards/grpo_reward_func/std': 0.3854354918003082,\n  'reward': 0.1796875,\n  'reward_std': 0.2909066081047058,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.0,\n  'epoch': 0.05333333333333334,\n  'step': 4},\n {'loss': -0.0,\n  'grad_norm': 14.42654800415039,\n  'learning_rate': 1.0000000000000002e-06,\n  'num_tokens': 114192.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2734375,\n  'rewards/grpo_reward_func/std': 0.447474867105484,\n  'reward': 0.2734375,\n  'reward_std': 0.3816412091255188,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.0,\n  'epoch': 0.06666666666666667,\n  'step': 5},\n {'loss': 0.0,\n  'grad_norm': 17.788265228271484,\n  'learning_rate': 2.0000000000000003e-06,\n  'num_tokens': 137456.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.25,\n  'rewards/grpo_reward_func/std': 0.434714138507843,\n  'reward': 0.25,\n  'reward_std': 0.3011612296104431,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 4.005618393421173e-05,\n  'epoch': 0.08,\n  'step': 6},\n {'loss': 0.0,\n  'grad_norm': nan,\n  'learning_rate': 3e-06,\n  'num_tokens': 161280.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3671875,\n  'rewards/grpo_reward_func/std': 0.4839322865009308,\n  'reward': 0.3671875,\n  'reward_std': 0.37298423051834106,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 3.948737867176533e-05,\n  'epoch': 0.09333333333333334,\n  'step': 7},\n {'loss': 0.0,\n  'grad_norm': 9.394168853759766,\n  'learning_rate': 3e-06,\n  'num_tokens': 184528.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.375,\n  'rewards/grpo_reward_func/std': 0.4860251843929291,\n  'reward': 0.375,\n  'reward_std': 0.2782978415489197,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 3.361562266945839e-05,\n  'epoch': 0.10666666666666667,\n  'step': 8},\n {'loss': 0.0,\n  'grad_norm': 11.71805477142334,\n  'learning_rate': 4.000000000000001e-06,\n  'num_tokens': 206592.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4296875,\n  'rewards/grpo_reward_func/std': 0.4969765841960907,\n  'reward': 0.4296875,\n  'reward_std': 0.4276527166366577,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 1.614028587937355e-05,\n  'epoch': 0.12,\n  'step': 9},\n {'loss': 0.0,\n  'grad_norm': 7.371083736419678,\n  'learning_rate': 5e-06,\n  'num_tokens': 229232.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3359375,\n  'rewards/grpo_reward_func/std': 0.47417303919792175,\n  'reward': 0.3359375,\n  'reward_std': 0.327734112739563,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 4.753214307129383e-05,\n  'epoch': 0.13333333333333333,\n  'step': 10},\n {'loss': 0.0,\n  'grad_norm': 10.346480369567871,\n  'learning_rate': 6e-06,\n  'num_tokens': 251808.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4453125,\n  'rewards/grpo_reward_func/std': 0.4989531338214874,\n  'reward': 0.4453125,\n  'reward_std': 0.3158818483352661,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 5.9093115851283073e-05,\n  'epoch': 0.14666666666666667,\n  'step': 11},\n {'loss': 0.0,\n  'grad_norm': 6.598033428192139,\n  'learning_rate': 7e-06,\n  'num_tokens': 273696.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2734375,\n  'rewards/grpo_reward_func/std': 0.447474867105484,\n  'reward': 0.2734375,\n  'reward_std': 0.25620076060295105,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 6.189709529280663e-05,\n  'epoch': 0.16,\n  'step': 12},\n {'loss': 0.0,\n  'grad_norm': 16.50634765625,\n  'learning_rate': 8.000000000000001e-06,\n  'num_tokens': 296013.0,\n  'completions/mean_length': 2.9765625,\n  'completions/min_length': 2.0,\n  'completions/max_length': 127.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.9765625,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 127.0,\n  'rewards/grpo_reward_func/mean': 0.34375,\n  'rewards/grpo_reward_func/std': 0.47682511806488037,\n  'reward': 0.34375,\n  'reward_std': 0.41770240664482117,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.9765625,\n  'kl': 5.076626712252619e-05,\n  'epoch': 0.17333333333333334,\n  'step': 13},\n {'loss': 0.0,\n  'grad_norm': 5.3422441482543945,\n  'learning_rate': 9e-06,\n  'num_tokens': 318573.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.265625,\n  'rewards/grpo_reward_func/std': 0.44340085983276367,\n  'reward': 0.265625,\n  'reward_std': 0.21040895581245422,\n  'frac_reward_zero_std': 0.5625,\n  'completion_length': 2.0,\n  'kl': 7.036351598799229e-05,\n  'epoch': 0.18666666666666668,\n  'step': 14},\n {'loss': 0.0,\n  'grad_norm': 8.5847749710083,\n  'learning_rate': 1e-05,\n  'num_tokens': 341693.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.28125,\n  'rewards/grpo_reward_func/std': 0.4513758420944214,\n  'reward': 0.28125,\n  'reward_std': 0.36956924200057983,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.0001155028585344553,\n  'epoch': 0.2,\n  'step': 15},\n {'loss': 0.0,\n  'grad_norm': 9.988883018493652,\n  'learning_rate': 9.88888888888889e-06,\n  'num_tokens': 365133.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.484375,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.484375,\n  'reward_std': 0.345874547958374,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.00017576944082975388,\n  'epoch': 0.21333333333333335,\n  'step': 16},\n {'loss': 0.0,\n  'grad_norm': 7.6801629066467285,\n  'learning_rate': 9.777777777777779e-06,\n  'num_tokens': 388338.0,\n  'completions/mean_length': 3.0390625,\n  'completions/min_length': 2.0,\n  'completions/max_length': 135.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 3.0390625,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 135.0,\n  'rewards/grpo_reward_func/mean': 0.234375,\n  'rewards/grpo_reward_func/std': 0.42527204751968384,\n  'reward': 0.234375,\n  'reward_std': 0.2398776262998581,\n  'frac_reward_zero_std': 0.4375,\n  'completion_length': 3.0390625,\n  'kl': 0.0003720502427313477,\n  'epoch': 0.22666666666666666,\n  'step': 17},\n {'loss': 0.0,\n  'grad_norm': 6.17017126083374,\n  'learning_rate': 9.666666666666667e-06,\n  'num_tokens': 411826.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.28125,\n  'rewards/grpo_reward_func/std': 0.4513758420944214,\n  'reward': 0.28125,\n  'reward_std': 0.3571802079677582,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.000925139058381319,\n  'epoch': 0.24,\n  'step': 18},\n {'loss': 0.0,\n  'grad_norm': 6.848754405975342,\n  'learning_rate': 9.555555555555556e-06,\n  'num_tokens': 434434.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2421875,\n  'rewards/grpo_reward_func/std': 0.4300905168056488,\n  'reward': 0.2421875,\n  'reward_std': 0.3090519309043884,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.0013321912847459316,\n  'epoch': 0.25333333333333335,\n  'step': 19},\n {'loss': 0.0,\n  'grad_norm': 17.380708694458008,\n  'learning_rate': 9.444444444444445e-06,\n  'num_tokens': 457794.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.3882337510585785,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.0011746217496693134,\n  'epoch': 0.26666666666666666,\n  'step': 20},\n {'loss': 0.0,\n  'grad_norm': 14.098309516906738,\n  'learning_rate': 9.333333333333334e-06,\n  'num_tokens': 480338.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.171875,\n  'rewards/grpo_reward_func/std': 0.3787541687488556,\n  'reward': 0.171875,\n  'reward_std': 0.30221718549728394,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.0012965663336217403,\n  'epoch': 0.28,\n  'step': 21},\n {'loss': 0.0,\n  'grad_norm': 14.659856796264648,\n  'learning_rate': 9.222222222222224e-06,\n  'num_tokens': 503138.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4140625,\n  'rewards/grpo_reward_func/std': 0.49449479579925537,\n  'reward': 0.4140625,\n  'reward_std': 0.4479275941848755,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.005661458941176534,\n  'epoch': 0.29333333333333333,\n  'step': 22},\n {'loss': 0.0,\n  'grad_norm': 10.934754371643066,\n  'learning_rate': 9.111111111111112e-06,\n  'num_tokens': 525522.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3828125,\n  'rewards/grpo_reward_func/std': 0.4879830479621887,\n  'reward': 0.3828125,\n  'reward_std': 0.29196253418922424,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.002501123119145632,\n  'epoch': 0.30666666666666664,\n  'step': 23},\n {'loss': 0.0,\n  'grad_norm': 12.036635398864746,\n  'learning_rate': 9e-06,\n  'num_tokens': 548338.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2109375,\n  'rewards/grpo_reward_func/std': 0.4095771610736847,\n  'reward': 0.2109375,\n  'reward_std': 0.2772369980812073,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.006098786601796746,\n  'epoch': 0.32,\n  'step': 24},\n {'loss': 0.0,\n  'grad_norm': 14.533445358276367,\n  'learning_rate': 8.888888888888888e-06,\n  'num_tokens': 570450.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.1953125,\n  'rewards/grpo_reward_func/std': 0.3979988098144531,\n  'reward': 0.1953125,\n  'reward_std': 0.26698726415634155,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.004345896188169718,\n  'epoch': 0.3333333333333333,\n  'step': 25},\n {'loss': 0.0,\n  'grad_norm': 7.969460487365723,\n  'learning_rate': 8.777777777777778e-06,\n  'num_tokens': 593954.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.421875,\n  'rewards/grpo_reward_func/std': 0.4957992732524872,\n  'reward': 0.421875,\n  'reward_std': 0.33797892928123474,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.0033447614405304193,\n  'epoch': 0.3466666666666667,\n  'step': 26},\n {'loss': 0.0001,\n  'grad_norm': 9.673898696899414,\n  'learning_rate': 8.666666666666668e-06,\n  'num_tokens': 617618.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3046875,\n  'rewards/grpo_reward_func/std': 0.46208351850509644,\n  'reward': 0.3046875,\n  'reward_std': 0.40107494592666626,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.008915739832445979,\n  'epoch': 0.36,\n  'step': 27},\n {'loss': 0.0,\n  'grad_norm': 5.408391952514648,\n  'learning_rate': 8.555555555555556e-06,\n  'num_tokens': 641362.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.46875,\n  'rewards/grpo_reward_func/std': 0.5009832978248596,\n  'reward': 0.46875,\n  'reward_std': 0.2777610421180725,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.004860927117988467,\n  'epoch': 0.37333333333333335,\n  'step': 28},\n {'loss': 0.0001,\n  'grad_norm': 18.776357650756836,\n  'learning_rate': 8.444444444444446e-06,\n  'num_tokens': 663746.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3046875,\n  'rewards/grpo_reward_func/std': 0.46208351850509644,\n  'reward': 0.3046875,\n  'reward_std': 0.43949517607688904,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.008940784260630608,\n  'epoch': 0.38666666666666666,\n  'step': 29},\n {'loss': 0.0002,\n  'grad_norm': 10.115971565246582,\n  'learning_rate': 8.333333333333334e-06,\n  'num_tokens': 685650.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3203125,\n  'rewards/grpo_reward_func/std': 0.4684300124645233,\n  'reward': 0.3203125,\n  'reward_std': 0.3106446862220764,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.019696000963449478,\n  'epoch': 0.4,\n  'step': 30},\n {'loss': 0.0002,\n  'grad_norm': 17.29233741760254,\n  'learning_rate': 8.222222222222222e-06,\n  'num_tokens': 708882.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3984375,\n  'rewards/grpo_reward_func/std': 0.4915000796318054,\n  'reward': 0.3984375,\n  'reward_std': 0.39690351486206055,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.019988981308415532,\n  'epoch': 0.41333333333333333,\n  'step': 31},\n {'loss': 0.0002,\n  'grad_norm': 28.65237808227539,\n  'learning_rate': 8.111111111111112e-06,\n  'num_tokens': 731842.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2578125,\n  'rewards/grpo_reward_func/std': 0.43914902210235596,\n  'reward': 0.2578125,\n  'reward_std': 0.41793978214263916,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.021405593492090702,\n  'epoch': 0.4266666666666667,\n  'step': 32},\n {'loss': 0.0002,\n  'grad_norm': 9.880436897277832,\n  'learning_rate': 8.000000000000001e-06,\n  'num_tokens': 753122.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3984375,\n  'rewards/grpo_reward_func/std': 0.4915000796318054,\n  'reward': 0.3984375,\n  'reward_std': 0.4242328703403473,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.02170156827196479,\n  'epoch': 0.44,\n  'step': 33},\n {'loss': 0.0001,\n  'grad_norm': 14.864090919494629,\n  'learning_rate': 7.88888888888889e-06,\n  'num_tokens': 775762.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3359375,\n  'rewards/grpo_reward_func/std': 0.47417303919792175,\n  'reward': 0.3359375,\n  'reward_std': 0.31140607595443726,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.014650938799604774,\n  'epoch': 0.4533333333333333,\n  'step': 34},\n {'loss': 0.0002,\n  'grad_norm': 18.197364807128906,\n  'learning_rate': 7.77777777777778e-06,\n  'num_tokens': 798834.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.421875,\n  'rewards/grpo_reward_func/std': 0.4957992732524872,\n  'reward': 0.421875,\n  'reward_std': 0.4111049771308899,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.0239916336722672,\n  'epoch': 0.4666666666666667,\n  'step': 35},\n {'loss': 0.0002,\n  'grad_norm': 10.582185745239258,\n  'learning_rate': 7.666666666666667e-06,\n  'num_tokens': 822242.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4140625,\n  'rewards/grpo_reward_func/std': 0.49449479579925537,\n  'reward': 0.4140625,\n  'reward_std': 0.2619747221469879,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.021848865086212754,\n  'epoch': 0.48,\n  'step': 36},\n {'loss': 0.0003,\n  'grad_norm': 10.101689338684082,\n  'learning_rate': 7.555555555555556e-06,\n  'num_tokens': 844834.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.375,\n  'rewards/grpo_reward_func/std': 0.4860251843929291,\n  'reward': 0.375,\n  'reward_std': 0.39188605546951294,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.03432185668498278,\n  'epoch': 0.49333333333333335,\n  'step': 37},\n {'loss': 0.0003,\n  'grad_norm': 15.327982902526855,\n  'learning_rate': 7.444444444444445e-06,\n  'num_tokens': 867682.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4609375,\n  'rewards/grpo_reward_func/std': 0.5004304051399231,\n  'reward': 0.4609375,\n  'reward_std': 0.4016117453575134,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.0346230324357748,\n  'epoch': 0.5066666666666667,\n  'step': 38},\n {'loss': 0.0004,\n  'grad_norm': 9.168336868286133,\n  'learning_rate': 7.333333333333333e-06,\n  'num_tokens': 890402.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2890625,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.2890625,\n  'reward_std': 0.2835301160812378,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.054623650619760156,\n  'epoch': 0.52,\n  'step': 39},\n {'loss': 0.0006,\n  'grad_norm': 8.232376098632812,\n  'learning_rate': 7.222222222222223e-06,\n  'num_tokens': 913314.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3046875,\n  'rewards/grpo_reward_func/std': 0.46208351850509644,\n  'reward': 0.3046875,\n  'reward_std': 0.3514111638069153,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.0789250461384654,\n  'epoch': 0.5333333333333333,\n  'step': 40},\n {'loss': 0.0004,\n  'grad_norm': 9.514792442321777,\n  'learning_rate': 7.111111111111112e-06,\n  'num_tokens': 936745.0,\n  'completions/mean_length': 3.0546875,\n  'completions/min_length': 2.0,\n  'completions/max_length': 137.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 3.0546875,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 137.0,\n  'rewards/grpo_reward_func/mean': 0.2109375,\n  'rewards/grpo_reward_func/std': 0.4095771610736847,\n  'reward': 0.2109375,\n  'reward_std': 0.3050953149795532,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 3.0546875,\n  'kl': 0.05066233407706022,\n  'epoch': 0.5466666666666666,\n  'step': 41},\n {'loss': 0.0007,\n  'grad_norm': 12.245794296264648,\n  'learning_rate': 7e-06,\n  'num_tokens': 959593.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3203125,\n  'rewards/grpo_reward_func/std': 0.4684300124645233,\n  'reward': 0.3203125,\n  'reward_std': 0.4208228290081024,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.08802606165409088,\n  'epoch': 0.56,\n  'step': 42},\n {'loss': 0.0006,\n  'grad_norm': 12.157858848571777,\n  'learning_rate': 6.88888888888889e-06,\n  'num_tokens': 982249.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.328125,\n  'rewards/grpo_reward_func/std': 0.4713755249977112,\n  'reward': 0.328125,\n  'reward_std': 0.3942401707172394,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.07676143059507012,\n  'epoch': 0.5733333333333334,\n  'step': 43},\n {'loss': 0.0008,\n  'grad_norm': 25.45551109313965,\n  'learning_rate': 6.777777777777779e-06,\n  'num_tokens': 1004921.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3515625,\n  'rewards/grpo_reward_func/std': 0.4793342351913452,\n  'reward': 0.3515625,\n  'reward_std': 0.37480151653289795,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.09651223476976156,\n  'epoch': 0.5866666666666667,\n  'step': 44},\n {'loss': 0.0005,\n  'grad_norm': 14.910971641540527,\n  'learning_rate': 6.666666666666667e-06,\n  'num_tokens': 1028553.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3828125,\n  'rewards/grpo_reward_func/std': 0.4879830479621887,\n  'reward': 0.3828125,\n  'reward_std': 0.4410976767539978,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.06863310211338103,\n  'epoch': 0.6,\n  'step': 45},\n {'loss': 0.0005,\n  'grad_norm': 19.99220085144043,\n  'learning_rate': 6.555555555555556e-06,\n  'num_tokens': 1050825.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.21875,\n  'rewards/grpo_reward_func/std': 0.41502299904823303,\n  'reward': 0.21875,\n  'reward_std': 0.33797892928123474,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.05784555873833597,\n  'epoch': 0.6133333333333333,\n  'step': 46},\n {'loss': 0.0011,\n  'grad_norm': 9.052589416503906,\n  'learning_rate': 6.444444444444445e-06,\n  'num_tokens': 1073801.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3984375,\n  'rewards/grpo_reward_func/std': 0.4915000796318054,\n  'reward': 0.3984375,\n  'reward_std': 0.36584997177124023,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.13774855248630047,\n  'epoch': 0.6266666666666667,\n  'step': 47},\n {'loss': 0.001,\n  'grad_norm': 14.15621280670166,\n  'learning_rate': 6.333333333333333e-06,\n  'num_tokens': 1096937.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.4776257574558258,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.12851729337126017,\n  'epoch': 0.64,\n  'step': 48},\n {'loss': 0.0012,\n  'grad_norm': 13.2433500289917,\n  'learning_rate': 6.222222222222223e-06,\n  'num_tokens': 1119881.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2578125,\n  'rewards/grpo_reward_func/std': 0.43914902210235596,\n  'reward': 0.2578125,\n  'reward_std': 0.4013792872428894,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.14960897248238325,\n  'epoch': 0.6533333333333333,\n  'step': 49},\n {'loss': 0.0009,\n  'grad_norm': 17.991636276245117,\n  'learning_rate': 6.111111111111112e-06,\n  'num_tokens': 1142624.0,\n  'completions/mean_length': 2.3046875,\n  'completions/min_length': 2.0,\n  'completions/max_length': 41.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.3046875,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 41.0,\n  'rewards/grpo_reward_func/mean': 0.359375,\n  'rewards/grpo_reward_func/std': 0.481702595949173,\n  'reward': 0.359375,\n  'reward_std': 0.4292503595352173,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.3046875,\n  'kl': 0.11460193386301398,\n  'epoch': 0.6666666666666666,\n  'step': 50},\n {'loss': 0.0016,\n  'grad_norm': 17.65962028503418,\n  'learning_rate': 6e-06,\n  'num_tokens': 1164752.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3359375,\n  'rewards/grpo_reward_func/std': 0.47417303919792175,\n  'reward': 0.3359375,\n  'reward_std': 0.34586966037750244,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.19391293451189995,\n  'epoch': 0.68,\n  'step': 51},\n {'loss': 0.0011,\n  'grad_norm': 10.043134689331055,\n  'learning_rate': 5.88888888888889e-06,\n  'num_tokens': 1187088.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.40267258882522583,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.1339653069153428,\n  'epoch': 0.6933333333333334,\n  'step': 52},\n {'loss': 0.0015,\n  'grad_norm': 21.97630500793457,\n  'learning_rate': 5.777777777777778e-06,\n  'num_tokens': 1209296.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.578125,\n  'rewards/grpo_reward_func/std': 0.4957992732524872,\n  'reward': 0.578125,\n  'reward_std': 0.4508057236671448,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.1842742869630456,\n  'epoch': 0.7066666666666667,\n  'step': 53},\n {'loss': 0.0012,\n  'grad_norm': 15.157203674316406,\n  'learning_rate': 5.666666666666667e-06,\n  'num_tokens': 1231616.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.484375,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.484375,\n  'reward_std': 0.4258304834365845,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.1488081282004714,\n  'epoch': 0.72,\n  'step': 54},\n {'loss': 0.0015,\n  'grad_norm': 11.23808479309082,\n  'learning_rate': 5.555555555555557e-06,\n  'num_tokens': 1255312.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.40625,\n  'rewards/grpo_reward_func/std': 0.4930621087551117,\n  'reward': 0.40625,\n  'reward_std': 0.4542255699634552,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.18281775247305632,\n  'epoch': 0.7333333333333333,\n  'step': 55},\n {'loss': 0.0009,\n  'grad_norm': 10.9959716796875,\n  'learning_rate': 5.444444444444445e-06,\n  'num_tokens': 1278912.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4453125,\n  'rewards/grpo_reward_func/std': 0.4989531338214874,\n  'reward': 0.4453125,\n  'reward_std': 0.422415554523468,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.11082341056317091,\n  'epoch': 0.7466666666666667,\n  'step': 56},\n {'loss': 0.0014,\n  'grad_norm': 17.130599975585938,\n  'learning_rate': 5.333333333333334e-06,\n  'num_tokens': 1300448.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5390625,\n  'rewards/grpo_reward_func/std': 0.5004304051399231,\n  'reward': 0.5390625,\n  'reward_std': 0.44503670930862427,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.18108727503567934,\n  'epoch': 0.76,\n  'step': 57},\n {'loss': 0.0016,\n  'grad_norm': 14.126036643981934,\n  'learning_rate': 5.2222222222222226e-06,\n  'num_tokens': 1323040.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4296875,\n  'rewards/grpo_reward_func/std': 0.4969765841960907,\n  'reward': 0.4296875,\n  'reward_std': 0.42187875509262085,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.20417133904993534,\n  'epoch': 0.7733333333333333,\n  'step': 58},\n {'loss': 0.002,\n  'grad_norm': 15.366253852844238,\n  'learning_rate': 5.1111111111111115e-06,\n  'num_tokens': 1346176.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4453125,\n  'rewards/grpo_reward_func/std': 0.4989531338214874,\n  'reward': 0.4453125,\n  'reward_std': 0.4082092046737671,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.25069501623511314,\n  'epoch': 0.7866666666666666,\n  'step': 59},\n {'loss': 0.0023,\n  'grad_norm': 13.474246978759766,\n  'learning_rate': 5e-06,\n  'num_tokens': 1368736.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.53125,\n  'rewards/grpo_reward_func/std': 0.5009832978248596,\n  'reward': 0.53125,\n  'reward_std': 0.48763322830200195,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.2854534275829792,\n  'epoch': 0.8,\n  'step': 60},\n {'loss': 0.001,\n  'grad_norm': 13.552038192749023,\n  'learning_rate': 4.888888888888889e-06,\n  'num_tokens': 1393168.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2890625,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.2890625,\n  'reward_std': 0.3003949522972107,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.1283871536143124,\n  'epoch': 0.8133333333333334,\n  'step': 61},\n {'loss': 0.0022,\n  'grad_norm': 7.27840518951416,\n  'learning_rate': 4.777777777777778e-06,\n  'num_tokens': 1416816.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.40625,\n  'rewards/grpo_reward_func/std': 0.4930621087551117,\n  'reward': 0.40625,\n  'reward_std': 0.3516485095024109,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.27477441541850567,\n  'epoch': 0.8266666666666667,\n  'step': 62},\n {'loss': 0.0024,\n  'grad_norm': 23.44399070739746,\n  'learning_rate': 4.666666666666667e-06,\n  'num_tokens': 1438640.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.3634909391403198,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.2961214128881693,\n  'epoch': 0.84,\n  'step': 63},\n {'loss': 0.0015,\n  'grad_norm': 11.51883602142334,\n  'learning_rate': 4.555555555555556e-06,\n  'num_tokens': 1461104.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.46875,\n  'rewards/grpo_reward_func/std': 0.5009832978248596,\n  'reward': 0.46875,\n  'reward_std': 0.4481472969055176,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.18737037852406502,\n  'epoch': 0.8533333333333334,\n  'step': 64},\n {'loss': 0.0023,\n  'grad_norm': 13.838980674743652,\n  'learning_rate': 4.444444444444444e-06,\n  'num_tokens': 1483568.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2890625,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.2890625,\n  'reward_std': 0.35165339708328247,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.2934968192130327,\n  'epoch': 0.8666666666666667,\n  'step': 65},\n {'loss': 0.0027,\n  'grad_norm': 16.72353744506836,\n  'learning_rate': 4.333333333333334e-06,\n  'num_tokens': 1506288.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.375,\n  'rewards/grpo_reward_func/std': 0.4860251843929291,\n  'reward': 0.375,\n  'reward_std': 0.38717782497406006,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.33187502808868885,\n  'epoch': 0.88,\n  'step': 66},\n {'loss': 0.0019,\n  'grad_norm': 14.716371536254883,\n  'learning_rate': 4.222222222222223e-06,\n  'num_tokens': 1529440.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.515625,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.515625,\n  'reward_std': 0.46948787569999695,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.23352250829339027,\n  'epoch': 0.8933333333333333,\n  'step': 67},\n {'loss': 0.0023,\n  'grad_norm': 15.794472694396973,\n  'learning_rate': 4.111111111111111e-06,\n  'num_tokens': 1551248.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3984375,\n  'rewards/grpo_reward_func/std': 0.4915000796318054,\n  'reward': 0.3984375,\n  'reward_std': 0.40032336115837097,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.28410663455724716,\n  'epoch': 0.9066666666666666,\n  'step': 68},\n {'loss': 0.0025,\n  'grad_norm': 11.727340698242188,\n  'learning_rate': 4.000000000000001e-06,\n  'num_tokens': 1573568.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.34375,\n  'rewards/grpo_reward_func/std': 0.47682511806488037,\n  'reward': 0.34375,\n  'reward_std': 0.44397586584091187,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.3106748517602682,\n  'epoch': 0.92,\n  'step': 69},\n {'loss': 0.0025,\n  'grad_norm': 16.143686294555664,\n  'learning_rate': 3.88888888888889e-06,\n  'num_tokens': 1596944.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4921875,\n  'rewards/grpo_reward_func/std': 0.5019033551216125,\n  'reward': 0.4921875,\n  'reward_std': 0.4263545274734497,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.31346307322382927,\n  'epoch': 0.9333333333333333,\n  'step': 70},\n {'loss': 0.0026,\n  'grad_norm': 12.920327186584473,\n  'learning_rate': 3.777777777777778e-06,\n  'num_tokens': 1619808.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4609375,\n  'rewards/grpo_reward_func/std': 0.5004304051399231,\n  'reward': 0.4609375,\n  'reward_std': 0.3974226713180542,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.32159051671624184,\n  'epoch': 0.9466666666666667,\n  'step': 71},\n {'loss': 0.0027,\n  'grad_norm': 13.845372200012207,\n  'learning_rate': 3.6666666666666666e-06,\n  'num_tokens': 1643424.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4921875,\n  'rewards/grpo_reward_func/std': 0.5019033551216125,\n  'reward': 0.4921875,\n  'reward_std': 0.4752667546272278,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.33743781596422195,\n  'epoch': 0.96,\n  'step': 72},\n {'loss': 0.0031,\n  'grad_norm': 15.752296447753906,\n  'learning_rate': 3.555555555555556e-06,\n  'num_tokens': 1666720.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3125,\n  'rewards/grpo_reward_func/std': 0.4653336703777313,\n  'reward': 0.3125,\n  'reward_std': 0.35954412817955017,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.3864155635237694,\n  'epoch': 0.9733333333333334,\n  'step': 73},\n {'loss': 0.003,\n  'grad_norm': 30.762147903442383,\n  'learning_rate': 3.444444444444445e-06,\n  'num_tokens': 1690864.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3828125,\n  'rewards/grpo_reward_func/std': 0.4879830479621887,\n  'reward': 0.3828125,\n  'reward_std': 0.3306073546409607,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.37439601868391037,\n  'epoch': 0.9866666666666667,\n  'step': 74},\n {'loss': 0.0021,\n  'grad_norm': 30.284515380859375,\n  'learning_rate': 3.3333333333333333e-06,\n  'num_tokens': 1714192.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.375,\n  'rewards/grpo_reward_func/std': 0.4860251843929291,\n  'reward': 0.375,\n  'reward_std': 0.45104798674583435,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.2598338294774294,\n  'epoch': 1.0,\n  'step': 75},\n {'loss': 0.0028,\n  'grad_norm': 16.15115737915039,\n  'learning_rate': 3.2222222222222227e-06,\n  'num_tokens': 1736224.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4609375,\n  'rewards/grpo_reward_func/std': 0.5004304051399231,\n  'reward': 0.4609375,\n  'reward_std': 0.4303111433982849,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.35255683213472366,\n  'epoch': 1.0133333333333334,\n  'step': 76},\n {'loss': 0.0032,\n  'grad_norm': 21.270278930664062,\n  'learning_rate': 3.1111111111111116e-06,\n  'num_tokens': 1759600.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.71875,\n  'rewards/grpo_reward_func/std': 0.4513758420944214,\n  'reward': 0.71875,\n  'reward_std': 0.3692649006843567,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.40529369935393333,\n  'epoch': 1.0266666666666666,\n  'step': 77},\n {'loss': 0.003,\n  'grad_norm': 12.204743385314941,\n  'learning_rate': 3e-06,\n  'num_tokens': 1781600.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.34375,\n  'rewards/grpo_reward_func/std': 0.47682511806488037,\n  'reward': 0.34375,\n  'reward_std': 0.37822628021240234,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.3797241449356079,\n  'epoch': 1.04,\n  'step': 78},\n {'loss': 0.0048,\n  'grad_norm': 14.807944297790527,\n  'learning_rate': 2.888888888888889e-06,\n  'num_tokens': 1803808.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.515625,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.515625,\n  'reward_std': 0.40821409225463867,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.601512972265482,\n  'epoch': 1.0533333333333332,\n  'step': 79},\n {'loss': 0.0039,\n  'grad_norm': 10.425466537475586,\n  'learning_rate': 2.7777777777777783e-06,\n  'num_tokens': 1827584.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.4434567093849182,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.4879078231751919,\n  'epoch': 1.0666666666666667,\n  'step': 80},\n {'loss': 0.0031,\n  'grad_norm': 12.901190757751465,\n  'learning_rate': 2.666666666666667e-06,\n  'num_tokens': 1850304.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.40625,\n  'rewards/grpo_reward_func/std': 0.4930621087551117,\n  'reward': 0.40625,\n  'reward_std': 0.404032826423645,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.38930613175034523,\n  'epoch': 1.08,\n  'step': 81},\n {'loss': 0.0025,\n  'grad_norm': 13.081315994262695,\n  'learning_rate': 2.5555555555555557e-06,\n  'num_tokens': 1873568.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.3908301293849945,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.3112834319472313,\n  'epoch': 1.0933333333333333,\n  'step': 82},\n {'loss': 0.0033,\n  'grad_norm': 13.137141227722168,\n  'learning_rate': 2.4444444444444447e-06,\n  'num_tokens': 1896160.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.40625,\n  'rewards/grpo_reward_func/std': 0.4930621087551117,\n  'reward': 0.40625,\n  'reward_std': 0.39400771260261536,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.410469725728035,\n  'epoch': 1.1066666666666667,\n  'step': 83},\n {'loss': 0.0046,\n  'grad_norm': 18.9366512298584,\n  'learning_rate': 2.3333333333333336e-06,\n  'num_tokens': 1919088.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3515625,\n  'rewards/grpo_reward_func/std': 0.4793342351913452,\n  'reward': 0.3515625,\n  'reward_std': 0.39690351486206055,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.5758501496165991,\n  'epoch': 1.12,\n  'step': 84},\n {'loss': 0.0032,\n  'grad_norm': 28.156539916992188,\n  'learning_rate': 2.222222222222222e-06,\n  'num_tokens': 1942756.0,\n  'completions/mean_length': 2.40625,\n  'completions/min_length': 2.0,\n  'completions/max_length': 54.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.40625,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 54.0,\n  'rewards/grpo_reward_func/mean': 0.515625,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.515625,\n  'reward_std': 0.4082140624523163,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.40625,\n  'kl': 0.40275817923247814,\n  'epoch': 1.1333333333333333,\n  'step': 85},\n {'loss': 0.0036,\n  'grad_norm': 26.935487747192383,\n  'learning_rate': 2.1111111111111114e-06,\n  'num_tokens': 1965284.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4140625,\n  'rewards/grpo_reward_func/std': 0.49449479579925537,\n  'reward': 0.4140625,\n  'reward_std': 0.38375309109687805,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.45430153980851173,\n  'epoch': 1.1466666666666667,\n  'step': 86},\n {'loss': 0.0039,\n  'grad_norm': 21.796457290649414,\n  'learning_rate': 2.0000000000000003e-06,\n  'num_tokens': 1988308.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.6328125,\n  'rewards/grpo_reward_func/std': 0.4839322865009308,\n  'reward': 0.6328125,\n  'reward_std': 0.38269713521003723,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.4891499653458595,\n  'epoch': 1.16,\n  'step': 87},\n {'loss': 0.0038,\n  'grad_norm': 21.261381149291992,\n  'learning_rate': 1.888888888888889e-06,\n  'num_tokens': 2011687.0,\n  'completions/mean_length': 3.1484375,\n  'completions/min_length': 2.0,\n  'completions/max_length': 149.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 3.1484375,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 149.0,\n  'rewards/grpo_reward_func/mean': 0.546875,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.546875,\n  'reward_std': 0.36691081523895264,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 3.1484375,\n  'kl': 0.4724932797253132,\n  'epoch': 1.1733333333333333,\n  'step': 88},\n {'loss': 0.004,\n  'grad_norm': 23.441123962402344,\n  'learning_rate': 1.777777777777778e-06,\n  'num_tokens': 2033783.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4765625,\n  'rewards/grpo_reward_func/std': 0.5014128684997559,\n  'reward': 0.4765625,\n  'reward_std': 0.47366422414779663,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.4950244463980198,\n  'epoch': 1.1866666666666668,\n  'step': 89},\n {'loss': 0.0041,\n  'grad_norm': 14.02473258972168,\n  'learning_rate': 1.6666666666666667e-06,\n  'num_tokens': 2056871.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.7109375,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.7109375,\n  'reward_std': 0.45688894391059875,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.5131862014532089,\n  'epoch': 1.2,\n  'step': 90},\n {'loss': 0.0033,\n  'grad_norm': 17.952314376831055,\n  'learning_rate': 1.5555555555555558e-06,\n  'num_tokens': 2079815.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3671875,\n  'rewards/grpo_reward_func/std': 0.4839322865009308,\n  'reward': 0.3671875,\n  'reward_std': 0.4331844449043274,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.4155934303998947,\n  'epoch': 1.2133333333333334,\n  'step': 91}]"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"print('Genering train data')\ntrain_dataset = PointSetGRPODataset(game, num_samples=1200, difficulties = [1])\n\ntraining_args = GRPOConfig(\n    output_dir=\"./point_set_agent\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=8,\n    learning_rate=1e-5,\n    optim=\"adamw_torch\",\n    max_steps=50,\n    logging_steps=1,\n    save_steps=50,\n    eval_steps=25,\n    warmup_steps=10,\n    fp16=True,\n    report_to=\"none\",\n    remove_unused_columns=False,\n)\n\ntrainer = GRPOTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    reward_funcs=[grpo_reward_func],\n    preprocess_logits_for_metrics=lambda logits, labels: logits.argmax(dim=-1),\n)\n\nprint(\"Starting training...\")\ntrainer.train()\nprint(\"Training completed successfully!\")","metadata":{"id":"1LhebDMKTwQS","trusted":true,"execution":{"iopub.status.busy":"2025-09-15T20:32:14.639505Z","iopub.execute_input":"2025-09-15T20:32:14.639702Z","iopub.status.idle":"2025-09-15T21:08:34.103410Z","shell.execute_reply.started":"2025-09-15T20:32:14.639686Z","shell.execute_reply":"2025-09-15T21:08:34.102532Z"}},"outputs":[{"name":"stdout","text":"Genering train data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\nThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\nWe will change the batch size of 1 to the `num_generations` of 8\nStarting training...\n","output_type":"stream"},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,200 | Num Epochs = 1 | Total steps = 50\nO^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 8 x 1) = 128\n \"-____-\"     Trainable parameters = 3,686,400 of 3,089,625,088 (0.12% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 33:10, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>reward</th>\n      <th>reward_std</th>\n      <th>completions / mean_length</th>\n      <th>completions / min_length</th>\n      <th>completions / max_length</th>\n      <th>completions / clipped_ratio</th>\n      <th>completions / mean_terminated_length</th>\n      <th>completions / min_terminated_length</th>\n      <th>completions / max_terminated_length</th>\n      <th>sampling / sampling_logp_difference / mean</th>\n      <th>sampling / sampling_logp_difference / max</th>\n      <th>sampling / importance_sampling_ratio / min</th>\n      <th>sampling / importance_sampling_ratio / mean</th>\n      <th>sampling / importance_sampling_ratio / max</th>\n      <th>kl</th>\n      <th>rewards / grpo_reward_func / mean</th>\n      <th>rewards / grpo_reward_func / std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>256.000000</td>\n      <td>256.000000</td>\n      <td>256.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>-0.000000</td>\n      <td>0.289062</td>\n      <td>0.410563</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000000</td>\n      <td>0.289062</td>\n      <td>0.455108</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>-0.000000</td>\n      <td>0.195312</td>\n      <td>0.336918</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000000</td>\n      <td>0.195312</td>\n      <td>0.397999</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>-0.000000</td>\n      <td>0.429688</td>\n      <td>0.360076</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000000</td>\n      <td>0.429688</td>\n      <td>0.496977</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>-0.000000</td>\n      <td>0.406250</td>\n      <td>0.374806</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000000</td>\n      <td>0.406250</td>\n      <td>0.493062</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.000000</td>\n      <td>0.281250</td>\n      <td>0.383990</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000037</td>\n      <td>0.281250</td>\n      <td>0.451376</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.000000</td>\n      <td>0.156250</td>\n      <td>0.254603</td>\n      <td>2.453125</td>\n      <td>2.000000</td>\n      <td>38.000000</td>\n      <td>0.000000</td>\n      <td>2.453125</td>\n      <td>2.000000</td>\n      <td>38.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000027</td>\n      <td>0.156250</td>\n      <td>0.364519</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000000</td>\n      <td>0.226562</td>\n      <td>0.296144</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000021</td>\n      <td>0.226562</td>\n      <td>0.420252</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000000</td>\n      <td>0.437500</td>\n      <td>0.412922</td>\n      <td>2.359375</td>\n      <td>2.000000</td>\n      <td>48.000000</td>\n      <td>0.000000</td>\n      <td>2.359375</td>\n      <td>2.000000</td>\n      <td>48.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000017</td>\n      <td>0.437500</td>\n      <td>0.498028</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000000</td>\n      <td>0.390625</td>\n      <td>0.341399</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000046</td>\n      <td>0.390625</td>\n      <td>0.489808</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.000000</td>\n      <td>0.359375</td>\n      <td>0.359015</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000020</td>\n      <td>0.359375</td>\n      <td>0.481703</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.000000</td>\n      <td>0.296875</td>\n      <td>0.400318</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000059</td>\n      <td>0.296875</td>\n      <td>0.458676</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.000000</td>\n      <td>0.289062</td>\n      <td>0.333266</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000079</td>\n      <td>0.289062</td>\n      <td>0.455108</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.000000</td>\n      <td>0.242188</td>\n      <td>0.309052</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000164</td>\n      <td>0.242188</td>\n      <td>0.430091</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.000000</td>\n      <td>0.406250</td>\n      <td>0.429008</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000349</td>\n      <td>0.406250</td>\n      <td>0.493062</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.000000</td>\n      <td>0.421875</td>\n      <td>0.378226</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000349</td>\n      <td>0.421875</td>\n      <td>0.495799</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.000000</td>\n      <td>0.218750</td>\n      <td>0.200696</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000584</td>\n      <td>0.218750</td>\n      <td>0.415023</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.000000</td>\n      <td>0.468750</td>\n      <td>0.350583</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.001276</td>\n      <td>0.468750</td>\n      <td>0.500983</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.000000</td>\n      <td>0.273438</td>\n      <td>0.272224</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.000976</td>\n      <td>0.273438</td>\n      <td>0.447475</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.000000</td>\n      <td>0.429688</td>\n      <td>0.421879</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.003231</td>\n      <td>0.429688</td>\n      <td>0.496977</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.000000</td>\n      <td>0.351562</td>\n      <td>0.447928</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.003222</td>\n      <td>0.351562</td>\n      <td>0.479334</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.000000</td>\n      <td>0.375000</td>\n      <td>0.449750</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.005485</td>\n      <td>0.375000</td>\n      <td>0.486025</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.000100</td>\n      <td>0.484375</td>\n      <td>0.453706</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.008254</td>\n      <td>0.484375</td>\n      <td>0.501719</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.000100</td>\n      <td>0.257812</td>\n      <td>0.290370</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.007436</td>\n      <td>0.257812</td>\n      <td>0.439149</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.000100</td>\n      <td>0.296875</td>\n      <td>0.288011</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.009788</td>\n      <td>0.296875</td>\n      <td>0.458676</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.000100</td>\n      <td>0.351562</td>\n      <td>0.352709</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.018544</td>\n      <td>0.351562</td>\n      <td>0.479334</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.000100</td>\n      <td>0.421875</td>\n      <td>0.397964</td>\n      <td>2.367188</td>\n      <td>2.000000</td>\n      <td>49.000000</td>\n      <td>0.000000</td>\n      <td>2.367188</td>\n      <td>2.000000</td>\n      <td>49.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.016113</td>\n      <td>0.421875</td>\n      <td>0.495799</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.000100</td>\n      <td>0.320312</td>\n      <td>0.435548</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.016982</td>\n      <td>0.320312</td>\n      <td>0.468430</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.000200</td>\n      <td>0.453125</td>\n      <td>0.365613</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.020356</td>\n      <td>0.453125</td>\n      <td>0.499754</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.000200</td>\n      <td>0.328125</td>\n      <td>0.396362</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.024580</td>\n      <td>0.328125</td>\n      <td>0.471376</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.000300</td>\n      <td>0.273438</td>\n      <td>0.397959</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.034311</td>\n      <td>0.273438</td>\n      <td>0.447475</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.000300</td>\n      <td>0.289062</td>\n      <td>0.377997</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.035457</td>\n      <td>0.289062</td>\n      <td>0.455108</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.000400</td>\n      <td>0.335938</td>\n      <td>0.387173</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.054088</td>\n      <td>0.335938</td>\n      <td>0.474173</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.000400</td>\n      <td>0.546875</td>\n      <td>0.435024</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.048086</td>\n      <td>0.546875</td>\n      <td>0.499754</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.000600</td>\n      <td>0.359375</td>\n      <td>0.396899</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.070502</td>\n      <td>0.359375</td>\n      <td>0.481703</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.000400</td>\n      <td>0.343750</td>\n      <td>0.210946</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.047076</td>\n      <td>0.343750</td>\n      <td>0.476825</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.000400</td>\n      <td>0.531250</td>\n      <td>0.492109</td>\n      <td>2.187500</td>\n      <td>2.000000</td>\n      <td>26.000000</td>\n      <td>0.000000</td>\n      <td>2.187500</td>\n      <td>2.000000</td>\n      <td>26.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.052134</td>\n      <td>0.531250</td>\n      <td>0.500983</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.000400</td>\n      <td>0.367188</td>\n      <td>0.334027</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.053326</td>\n      <td>0.367188</td>\n      <td>0.483932</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.000400</td>\n      <td>0.312500</td>\n      <td>0.306693</td>\n      <td>3.914062</td>\n      <td>2.000000</td>\n      <td>247.000000</td>\n      <td>0.000000</td>\n      <td>3.914062</td>\n      <td>2.000000</td>\n      <td>247.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.043944</td>\n      <td>0.312500</td>\n      <td>0.465334</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.000400</td>\n      <td>0.382812</td>\n      <td>0.314584</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.046698</td>\n      <td>0.382812</td>\n      <td>0.487983</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.000700</td>\n      <td>0.351562</td>\n      <td>0.447391</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.084500</td>\n      <td>0.351562</td>\n      <td>0.479334</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.000400</td>\n      <td>0.554688</td>\n      <td>0.370638</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.055417</td>\n      <td>0.554688</td>\n      <td>0.498953</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.000400</td>\n      <td>0.570312</td>\n      <td>0.367972</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.056043</td>\n      <td>0.570312</td>\n      <td>0.496977</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.000400</td>\n      <td>0.460938</td>\n      <td>0.389008</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.055147</td>\n      <td>0.460938</td>\n      <td>0.500430</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.000500</td>\n      <td>0.414062</td>\n      <td>0.442915</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.057816</td>\n      <td>0.414062</td>\n      <td>0.494495</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.000500</td>\n      <td>0.546875</td>\n      <td>0.358478</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.060216</td>\n      <td>0.546875</td>\n      <td>0.499754</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.000500</td>\n      <td>0.375000</td>\n      <td>0.466078</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.067716</td>\n      <td>0.375000</td>\n      <td>0.486025</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.000500</td>\n      <td>0.312500</td>\n      <td>0.371387</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.057795</td>\n      <td>0.312500</td>\n      <td>0.465334</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.000500</td>\n      <td>0.445312</td>\n      <td>0.452646</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.056529</td>\n      <td>0.445312</td>\n      <td>0.498953</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.000400</td>\n      <td>0.335938</td>\n      <td>0.284596</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.047254</td>\n      <td>0.335938</td>\n      <td>0.474173</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"Training completed successfully!\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"trainer.state.log_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T21:08:34.104715Z","iopub.execute_input":"2025-09-15T21:08:34.104958Z","iopub.status.idle":"2025-09-15T21:08:34.125017Z","shell.execute_reply.started":"2025-09-15T21:08:34.104942Z","shell.execute_reply":"2025-09-15T21:08:34.124315Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[{'loss': 0.0,\n  'grad_norm': 0.0,\n  'learning_rate': 0.0,\n  'num_tokens': 49696.0,\n  'completions/mean_length': 256.0,\n  'completions/min_length': 256.0,\n  'completions/max_length': 256.0,\n  'completions/clipped_ratio': 1.0,\n  'completions/mean_terminated_length': 0.0,\n  'completions/min_terminated_length': 0.0,\n  'completions/max_terminated_length': 0.0,\n  'rewards/grpo_reward_func/mean': 0.0,\n  'rewards/grpo_reward_func/std': 0.0,\n  'reward': 0.0,\n  'reward_std': 0.0,\n  'frac_reward_zero_std': 1.0,\n  'completion_length': 256.0,\n  'kl': 0.0,\n  'epoch': 0.013333333333333334,\n  'step': 1},\n {'loss': -0.0,\n  'grad_norm': nan,\n  'learning_rate': 1.0000000000000002e-06,\n  'num_tokens': 66576.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2890625,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.2890625,\n  'reward_std': 0.41056329011917114,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.0,\n  'epoch': 0.02666666666666667,\n  'step': 2},\n {'loss': -0.0,\n  'grad_norm': nan,\n  'learning_rate': 1.0000000000000002e-06,\n  'num_tokens': 83552.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.1953125,\n  'rewards/grpo_reward_func/std': 0.3979988098144531,\n  'reward': 0.1953125,\n  'reward_std': 0.3369181156158447,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.0,\n  'epoch': 0.04,\n  'step': 3},\n {'loss': -0.0,\n  'grad_norm': nan,\n  'learning_rate': 1.0000000000000002e-06,\n  'num_tokens': 101168.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4296875,\n  'rewards/grpo_reward_func/std': 0.4969765841960907,\n  'reward': 0.4296875,\n  'reward_std': 0.36007601022720337,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.0,\n  'epoch': 0.05333333333333334,\n  'step': 4},\n {'loss': -0.0,\n  'grad_norm': 9.238960266113281,\n  'learning_rate': 1.0000000000000002e-06,\n  'num_tokens': 118208.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.40625,\n  'rewards/grpo_reward_func/std': 0.4930621087551117,\n  'reward': 0.40625,\n  'reward_std': 0.3748064339160919,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.0,\n  'epoch': 0.06666666666666667,\n  'step': 5},\n {'loss': 0.0,\n  'grad_norm': 12.46284008026123,\n  'learning_rate': 2.0000000000000003e-06,\n  'num_tokens': 135616.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.28125,\n  'rewards/grpo_reward_func/std': 0.4513758420944214,\n  'reward': 0.28125,\n  'reward_std': 0.38399040699005127,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 3.7328340113162994e-05,\n  'epoch': 0.08,\n  'step': 6},\n {'loss': 0.0,\n  'grad_norm': 12.369543075561523,\n  'learning_rate': 3e-06,\n  'num_tokens': 153450.0,\n  'completions/mean_length': 2.453125,\n  'completions/min_length': 2.0,\n  'completions/max_length': 38.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.453125,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 38.0,\n  'rewards/grpo_reward_func/mean': 0.15625,\n  'rewards/grpo_reward_func/std': 0.3645188808441162,\n  'reward': 0.15625,\n  'reward_std': 0.2546031177043915,\n  'frac_reward_zero_std': 0.4375,\n  'completion_length': 2.453125,\n  'kl': 2.6807176027432433e-05,\n  'epoch': 0.09333333333333334,\n  'step': 7},\n {'loss': 0.0,\n  'grad_norm': 12.77575969696045,\n  'learning_rate': 4.000000000000001e-06,\n  'num_tokens': 171018.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2265625,\n  'rewards/grpo_reward_func/std': 0.4202519655227661,\n  'reward': 0.2265625,\n  'reward_std': 0.2961437702178955,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 2.1158019080758095e-05,\n  'epoch': 0.10666666666666667,\n  'step': 8},\n {'loss': 0.0,\n  'grad_norm': 7.090888977050781,\n  'learning_rate': 5e-06,\n  'num_tokens': 188456.0,\n  'completions/mean_length': 2.359375,\n  'completions/min_length': 2.0,\n  'completions/max_length': 48.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.359375,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 48.0,\n  'rewards/grpo_reward_func/mean': 0.4375,\n  'rewards/grpo_reward_func/std': 0.49802759289741516,\n  'reward': 0.4375,\n  'reward_std': 0.41292232275009155,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.359375,\n  'kl': 1.6992717974062543e-05,\n  'epoch': 0.12,\n  'step': 9},\n {'loss': 0.0,\n  'grad_norm': nan,\n  'learning_rate': 6e-06,\n  'num_tokens': 206056.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.390625,\n  'rewards/grpo_reward_func/std': 0.4898075461387634,\n  'reward': 0.390625,\n  'reward_std': 0.34139877557754517,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 4.577497020363808e-05,\n  'epoch': 0.13333333333333333,\n  'step': 10},\n {'loss': 0.0,\n  'grad_norm': 5.9673895835876465,\n  'learning_rate': 6e-06,\n  'num_tokens': 222872.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.359375,\n  'rewards/grpo_reward_func/std': 0.481702595949173,\n  'reward': 0.359375,\n  'reward_std': 0.35901519656181335,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 2.0474428310990334e-05,\n  'epoch': 0.14666666666666667,\n  'step': 11},\n {'loss': 0.0,\n  'grad_norm': 14.012675285339355,\n  'learning_rate': 7e-06,\n  'num_tokens': 240552.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.296875,\n  'rewards/grpo_reward_func/std': 0.45867621898651123,\n  'reward': 0.296875,\n  'reward_std': 0.400318443775177,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 5.917227827012539e-05,\n  'epoch': 0.16,\n  'step': 12},\n {'loss': 0.0,\n  'grad_norm': 8.642964363098145,\n  'learning_rate': 8.000000000000001e-06,\n  'num_tokens': 257976.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2890625,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.2890625,\n  'reward_std': 0.3332657814025879,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 7.856939919292927e-05,\n  'epoch': 0.17333333333333334,\n  'step': 13},\n {'loss': 0.0,\n  'grad_norm': 7.4065093994140625,\n  'learning_rate': 9e-06,\n  'num_tokens': 275608.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2421875,\n  'rewards/grpo_reward_func/std': 0.4300905168056488,\n  'reward': 0.2421875,\n  'reward_std': 0.3090519309043884,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.00016411812976002693,\n  'epoch': 0.18666666666666668,\n  'step': 14},\n {'loss': 0.0,\n  'grad_norm': 16.034381866455078,\n  'learning_rate': 1e-05,\n  'num_tokens': 293256.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.40625,\n  'rewards/grpo_reward_func/std': 0.4930621087551117,\n  'reward': 0.40625,\n  'reward_std': 0.4290080666542053,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.00034890859387815,\n  'epoch': 0.2,\n  'step': 15},\n {'loss': 0.0,\n  'grad_norm': 15.617035865783691,\n  'learning_rate': 9.75e-06,\n  'num_tokens': 310648.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.421875,\n  'rewards/grpo_reward_func/std': 0.4957992732524872,\n  'reward': 0.421875,\n  'reward_std': 0.37822628021240234,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.0003490447998046875,\n  'epoch': 0.21333333333333335,\n  'step': 16},\n {'loss': 0.0,\n  'grad_norm': 12.740421295166016,\n  'learning_rate': 9.5e-06,\n  'num_tokens': 327688.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.21875,\n  'rewards/grpo_reward_func/std': 0.41502299904823303,\n  'reward': 0.21875,\n  'reward_std': 0.20069602131843567,\n  'frac_reward_zero_std': 0.5,\n  'completion_length': 2.0,\n  'kl': 0.0005839851219207048,\n  'epoch': 0.22666666666666666,\n  'step': 17},\n {'loss': 0.0,\n  'grad_norm': nan,\n  'learning_rate': 9.250000000000001e-06,\n  'num_tokens': 344712.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.46875,\n  'rewards/grpo_reward_func/std': 0.5009832978248596,\n  'reward': 0.46875,\n  'reward_std': 0.3505827784538269,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.0012760055251419544,\n  'epoch': 0.24,\n  'step': 18},\n {'loss': 0.0,\n  'grad_norm': 9.862725257873535,\n  'learning_rate': 9.250000000000001e-06,\n  'num_tokens': 362248.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2734375,\n  'rewards/grpo_reward_func/std': 0.447474867105484,\n  'reward': 0.2734375,\n  'reward_std': 0.27222445607185364,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.0009757701773196459,\n  'epoch': 0.25333333333333335,\n  'step': 19},\n {'loss': 0.0,\n  'grad_norm': 16.395700454711914,\n  'learning_rate': 9e-06,\n  'num_tokens': 379864.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4296875,\n  'rewards/grpo_reward_func/std': 0.4969765841960907,\n  'reward': 0.4296875,\n  'reward_std': 0.42187875509262085,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.003230811795219779,\n  'epoch': 0.26666666666666666,\n  'step': 20},\n {'loss': 0.0,\n  'grad_norm': 17.485456466674805,\n  'learning_rate': 8.750000000000001e-06,\n  'num_tokens': 397208.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3515625,\n  'rewards/grpo_reward_func/std': 0.4793342351913452,\n  'reward': 0.3515625,\n  'reward_std': 0.4479275941848755,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.0032216873951256275,\n  'epoch': 0.28,\n  'step': 21},\n {'loss': 0.0,\n  'grad_norm': 15.61159610748291,\n  'learning_rate': 8.5e-06,\n  'num_tokens': 414680.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.375,\n  'rewards/grpo_reward_func/std': 0.4860251843929291,\n  'reward': 0.375,\n  'reward_std': 0.44974982738494873,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.005485226633027196,\n  'epoch': 0.29333333333333333,\n  'step': 22},\n {'loss': 0.0001,\n  'grad_norm': 5.594305038452148,\n  'learning_rate': 8.25e-06,\n  'num_tokens': 431992.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.484375,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.484375,\n  'reward_std': 0.45370644330978394,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.008254139451310039,\n  'epoch': 0.30666666666666664,\n  'step': 23},\n {'loss': 0.0001,\n  'grad_norm': 13.246725082397461,\n  'learning_rate': 8.000000000000001e-06,\n  'num_tokens': 449112.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2578125,\n  'rewards/grpo_reward_func/std': 0.43914902210235596,\n  'reward': 0.2578125,\n  'reward_std': 0.29036980867385864,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.007435553707182407,\n  'epoch': 0.32,\n  'step': 24},\n {'loss': 0.0001,\n  'grad_norm': 14.345986366271973,\n  'learning_rate': 7.75e-06,\n  'num_tokens': 466040.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.296875,\n  'rewards/grpo_reward_func/std': 0.45867621898651123,\n  'reward': 0.296875,\n  'reward_std': 0.2880108058452606,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.009788007708266377,\n  'epoch': 0.3333333333333333,\n  'step': 25},\n {'loss': 0.0001,\n  'grad_norm': 10.646414756774902,\n  'learning_rate': 7.500000000000001e-06,\n  'num_tokens': 483416.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3515625,\n  'rewards/grpo_reward_func/std': 0.4793342351913452,\n  'reward': 0.3515625,\n  'reward_std': 0.3527093529701233,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.018543711164966226,\n  'epoch': 0.3466666666666667,\n  'step': 26},\n {'loss': 0.0001,\n  'grad_norm': 22.02495002746582,\n  'learning_rate': 7.25e-06,\n  'num_tokens': 501191.0,\n  'completions/mean_length': 2.3671875,\n  'completions/min_length': 2.0,\n  'completions/max_length': 49.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.3671875,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 49.0,\n  'rewards/grpo_reward_func/mean': 0.421875,\n  'rewards/grpo_reward_func/std': 0.4957992732524872,\n  'reward': 0.421875,\n  'reward_std': 0.39796435832977295,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.3671875,\n  'kl': 0.01611255039460957,\n  'epoch': 0.36,\n  'step': 27},\n {'loss': 0.0001,\n  'grad_norm': 17.491161346435547,\n  'learning_rate': 7e-06,\n  'num_tokens': 518679.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3203125,\n  'rewards/grpo_reward_func/std': 0.4684300124645233,\n  'reward': 0.3203125,\n  'reward_std': 0.435548335313797,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.01698221988044679,\n  'epoch': 0.37333333333333335,\n  'step': 28},\n {'loss': 0.0002,\n  'grad_norm': 8.555378913879395,\n  'learning_rate': 6.750000000000001e-06,\n  'num_tokens': 535943.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.36561262607574463,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.020356498891487718,\n  'epoch': 0.38666666666666666,\n  'step': 29},\n {'loss': 0.0002,\n  'grad_norm': 7.625484466552734,\n  'learning_rate': 6.5000000000000004e-06,\n  'num_tokens': 553223.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.328125,\n  'rewards/grpo_reward_func/std': 0.4713755249977112,\n  'reward': 0.328125,\n  'reward_std': 0.3963618278503418,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.024579565972089767,\n  'epoch': 0.4,\n  'step': 30},\n {'loss': 0.0003,\n  'grad_norm': 15.894845008850098,\n  'learning_rate': 6.25e-06,\n  'num_tokens': 570999.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2734375,\n  'rewards/grpo_reward_func/std': 0.447474867105484,\n  'reward': 0.2734375,\n  'reward_std': 0.397959440946579,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.03431138186715543,\n  'epoch': 0.41333333333333333,\n  'step': 31},\n {'loss': 0.0003,\n  'grad_norm': 16.451316833496094,\n  'learning_rate': 6e-06,\n  'num_tokens': 588951.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.2890625,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.2890625,\n  'reward_std': 0.3779967427253723,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.0354569039773196,\n  'epoch': 0.4266666666666667,\n  'step': 32},\n {'loss': 0.0004,\n  'grad_norm': 10.492953300476074,\n  'learning_rate': 5.75e-06,\n  'num_tokens': 605991.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3359375,\n  'rewards/grpo_reward_func/std': 0.47417303919792175,\n  'reward': 0.3359375,\n  'reward_std': 0.3871729075908661,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.05408767145127058,\n  'epoch': 0.44,\n  'step': 33},\n {'loss': 0.0004,\n  'grad_norm': 17.43918800354004,\n  'learning_rate': 5.500000000000001e-06,\n  'num_tokens': 622823.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.546875,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.546875,\n  'reward_std': 0.43502432107925415,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.04808557755313814,\n  'epoch': 0.4533333333333333,\n  'step': 34},\n {'loss': 0.0006,\n  'grad_norm': 11.807674407958984,\n  'learning_rate': 5.2500000000000006e-06,\n  'num_tokens': 640071.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.359375,\n  'rewards/grpo_reward_func/std': 0.481702595949173,\n  'reward': 0.359375,\n  'reward_std': 0.39689862728118896,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.07050181832164526,\n  'epoch': 0.4666666666666667,\n  'step': 35},\n {'loss': 0.0004,\n  'grad_norm': 7.34521484375,\n  'learning_rate': 5e-06,\n  'num_tokens': 657367.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.34375,\n  'rewards/grpo_reward_func/std': 0.47682511806488037,\n  'reward': 0.34375,\n  'reward_std': 0.2109457552433014,\n  'frac_reward_zero_std': 0.5,\n  'completion_length': 2.0,\n  'kl': 0.047076030634343624,\n  'epoch': 0.48,\n  'step': 36},\n {'loss': 0.0004,\n  'grad_norm': 12.202495574951172,\n  'learning_rate': 4.75e-06,\n  'num_tokens': 674911.0,\n  'completions/mean_length': 2.1875,\n  'completions/min_length': 2.0,\n  'completions/max_length': 26.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.1875,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 26.0,\n  'rewards/grpo_reward_func/mean': 0.53125,\n  'rewards/grpo_reward_func/std': 0.5009832978248596,\n  'reward': 0.53125,\n  'reward_std': 0.4921090006828308,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.1875,\n  'kl': 0.052133738761767745,\n  'epoch': 0.49333333333333335,\n  'step': 37},\n {'loss': 0.0004,\n  'grad_norm': 11.957061767578125,\n  'learning_rate': 4.5e-06,\n  'num_tokens': 691759.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3671875,\n  'rewards/grpo_reward_func/std': 0.4839322865009308,\n  'reward': 0.3671875,\n  'reward_std': 0.3340272009372711,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.0533257017377764,\n  'epoch': 0.5066666666666667,\n  'step': 38},\n {'loss': 0.0004,\n  'grad_norm': 7.065120697021484,\n  'learning_rate': 4.25e-06,\n  'num_tokens': 709460.0,\n  'completions/mean_length': 3.9140625,\n  'completions/min_length': 2.0,\n  'completions/max_length': 247.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 3.9140625,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 247.0,\n  'rewards/grpo_reward_func/mean': 0.3125,\n  'rewards/grpo_reward_func/std': 0.4653336703777313,\n  'reward': 0.3125,\n  'reward_std': 0.3066929578781128,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 3.9140625,\n  'kl': 0.04394433228299022,\n  'epoch': 0.52,\n  'step': 39},\n {'loss': 0.0004,\n  'grad_norm': 6.940674304962158,\n  'learning_rate': 4.000000000000001e-06,\n  'num_tokens': 727092.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3828125,\n  'rewards/grpo_reward_func/std': 0.4879830479621887,\n  'reward': 0.3828125,\n  'reward_std': 0.3145836591720581,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.04669793322682381,\n  'epoch': 0.5333333333333333,\n  'step': 40},\n {'loss': 0.0007,\n  'grad_norm': 21.629390716552734,\n  'learning_rate': 3.7500000000000005e-06,\n  'num_tokens': 745252.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3515625,\n  'rewards/grpo_reward_func/std': 0.4793342351913452,\n  'reward': 0.3515625,\n  'reward_std': 0.4473907947540283,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.08449999336153269,\n  'epoch': 0.5466666666666666,\n  'step': 41},\n {'loss': 0.0004,\n  'grad_norm': 6.962506294250488,\n  'learning_rate': 3.5e-06,\n  'num_tokens': 762996.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5546875,\n  'rewards/grpo_reward_func/std': 0.4989531338214874,\n  'reward': 0.5546875,\n  'reward_std': 0.3706378936767578,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.05541711486876011,\n  'epoch': 0.56,\n  'step': 42},\n {'loss': 0.0004,\n  'grad_norm': 6.131926536560059,\n  'learning_rate': 3.2500000000000002e-06,\n  'num_tokens': 780468.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5703125,\n  'rewards/grpo_reward_func/std': 0.4969765841960907,\n  'reward': 0.5703125,\n  'reward_std': 0.36797162890434265,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.05604322720319033,\n  'epoch': 0.5733333333333334,\n  'step': 43},\n {'loss': 0.0004,\n  'grad_norm': 12.989645004272461,\n  'learning_rate': 3e-06,\n  'num_tokens': 798340.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4609375,\n  'rewards/grpo_reward_func/std': 0.5004304051399231,\n  'reward': 0.4609375,\n  'reward_std': 0.38900789618492126,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.05514705181121826,\n  'epoch': 0.5866666666666667,\n  'step': 44},\n {'loss': 0.0005,\n  'grad_norm': 12.275483131408691,\n  'learning_rate': 2.7500000000000004e-06,\n  'num_tokens': 815780.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4140625,\n  'rewards/grpo_reward_func/std': 0.49449479579925537,\n  'reward': 0.4140625,\n  'reward_std': 0.44291502237319946,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.057815630454570055,\n  'epoch': 0.6,\n  'step': 45},\n {'loss': 0.0005,\n  'grad_norm': 12.135476112365723,\n  'learning_rate': 2.5e-06,\n  'num_tokens': 833220.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.546875,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.546875,\n  'reward_std': 0.3584783971309662,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.06021610205061734,\n  'epoch': 0.6133333333333333,\n  'step': 46},\n {'loss': 0.0005,\n  'grad_norm': 11.721019744873047,\n  'learning_rate': 2.25e-06,\n  'num_tokens': 850484.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.375,\n  'rewards/grpo_reward_func/std': 0.4860251843929291,\n  'reward': 0.375,\n  'reward_std': 0.4660778343677521,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.06771598570048809,\n  'epoch': 0.6266666666666667,\n  'step': 47},\n {'loss': 0.0005,\n  'grad_norm': 14.005448341369629,\n  'learning_rate': 2.0000000000000003e-06,\n  'num_tokens': 867940.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3125,\n  'rewards/grpo_reward_func/std': 0.4653336703777313,\n  'reward': 0.3125,\n  'reward_std': 0.3713865876197815,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.05779511807486415,\n  'epoch': 0.64,\n  'step': 48},\n {'loss': 0.0005,\n  'grad_norm': 10.719392776489258,\n  'learning_rate': 1.75e-06,\n  'num_tokens': 885476.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4453125,\n  'rewards/grpo_reward_func/std': 0.4989531338214874,\n  'reward': 0.4453125,\n  'reward_std': 0.45264559984207153,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.05652882298454642,\n  'epoch': 0.6533333333333333,\n  'step': 49},\n {'loss': 0.0004,\n  'grad_norm': 11.715341567993164,\n  'learning_rate': 1.5e-06,\n  'num_tokens': 902644.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3359375,\n  'rewards/grpo_reward_func/std': 0.47417303919792175,\n  'reward': 0.3359375,\n  'reward_std': 0.2845958471298218,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.04725426621735096,\n  'epoch': 0.6666666666666666,\n  'step': 50},\n {'train_runtime': 2176.2389,\n  'train_samples_per_second': 2.941,\n  'train_steps_per_second': 0.023,\n  'total_flos': 0.0,\n  'train_loss': 0.0001955157145857811,\n  'epoch': 0.6666666666666666,\n  'step': 50}]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print('Genering train data')\ntrain_dataset = PointSetGRPODataset(game, num_samples=1200, difficulties = [3])\n\ntraining_args = GRPOConfig(\n    output_dir=\"./point_set_agent\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=8,\n    learning_rate=1e-5,\n    optim=\"adamw_torch\",\n    max_steps=50,\n    logging_steps=1,\n    save_steps=50,\n    eval_steps=25,\n    warmup_steps=10,\n    fp16=True,\n    report_to=\"none\",\n    remove_unused_columns=False,\n)\n\ntrainer = GRPOTrainer(\n    model=trainer.model,\n    args=training_args,\n    train_dataset=train_dataset,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    reward_funcs=[grpo_reward_func],\n    preprocess_logits_for_metrics=lambda logits, labels: logits.argmax(dim=-1),\n)\n\nprint(\"Starting training...\")\ntrainer.train()\nprint(\"Training completed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T21:08:34.125986Z","iopub.execute_input":"2025-09-15T21:08:34.126240Z","iopub.status.idle":"2025-09-15T22:02:33.865747Z","shell.execute_reply.started":"2025-09-15T21:08:34.126225Z","shell.execute_reply":"2025-09-15T22:02:33.864513Z"}},"outputs":[{"name":"stdout","text":"Genering train data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\nWe will change the batch size of 1 to the `num_generations` of 8\nStarting training...\n","output_type":"stream"},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,200 | Num Epochs = 3 | Total steps = 200\nO^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 8 x 1) = 128\n \"-____-\"     Trainable parameters = 3,686,400 of 3,089,625,088 (0.12% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 60/200 52:34 < 2:06:53, 0.02 it/s, Epoch 0.79/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>reward</th>\n      <th>reward_std</th>\n      <th>completions / mean_length</th>\n      <th>completions / min_length</th>\n      <th>completions / max_length</th>\n      <th>completions / clipped_ratio</th>\n      <th>completions / mean_terminated_length</th>\n      <th>completions / min_terminated_length</th>\n      <th>completions / max_terminated_length</th>\n      <th>sampling / sampling_logp_difference / mean</th>\n      <th>sampling / sampling_logp_difference / max</th>\n      <th>sampling / importance_sampling_ratio / min</th>\n      <th>sampling / importance_sampling_ratio / mean</th>\n      <th>sampling / importance_sampling_ratio / max</th>\n      <th>kl</th>\n      <th>rewards / grpo_reward_func / mean</th>\n      <th>rewards / grpo_reward_func / std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000400</td>\n      <td>0.320312</td>\n      <td>0.367435</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.051834</td>\n      <td>0.320312</td>\n      <td>0.468430</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000600</td>\n      <td>0.414062</td>\n      <td>0.382697</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.073904</td>\n      <td>0.414062</td>\n      <td>0.494495</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000500</td>\n      <td>0.375000</td>\n      <td>0.394008</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.065984</td>\n      <td>0.375000</td>\n      <td>0.486025</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000500</td>\n      <td>0.343750</td>\n      <td>0.306156</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.058055</td>\n      <td>0.343750</td>\n      <td>0.476825</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000500</td>\n      <td>0.421875</td>\n      <td>0.297741</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.057817</td>\n      <td>0.421875</td>\n      <td>0.495799</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.000500</td>\n      <td>0.523438</td>\n      <td>0.378221</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.060604</td>\n      <td>0.523438</td>\n      <td>0.501413</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.000500</td>\n      <td>0.367188</td>\n      <td>0.424770</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.067321</td>\n      <td>0.367188</td>\n      <td>0.483932</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000400</td>\n      <td>0.476562</td>\n      <td>0.352709</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.046924</td>\n      <td>0.476562</td>\n      <td>0.501413</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000600</td>\n      <td>0.437500</td>\n      <td>0.244890</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.069799</td>\n      <td>0.437500</td>\n      <td>0.498028</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000600</td>\n      <td>0.710938</td>\n      <td>0.365313</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.072763</td>\n      <td>0.710938</td>\n      <td>0.455108</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.000500</td>\n      <td>0.460938</td>\n      <td>0.501298</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.058909</td>\n      <td>0.460938</td>\n      <td>0.500430</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.000500</td>\n      <td>0.281250</td>\n      <td>0.330083</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.061928</td>\n      <td>0.281250</td>\n      <td>0.451376</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.000500</td>\n      <td>0.257812</td>\n      <td>0.360076</td>\n      <td>3.882812</td>\n      <td>2.000000</td>\n      <td>243.000000</td>\n      <td>0.000000</td>\n      <td>3.882812</td>\n      <td>2.000000</td>\n      <td>243.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.057485</td>\n      <td>0.257812</td>\n      <td>0.439149</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.000600</td>\n      <td>0.632812</td>\n      <td>0.407690</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.080277</td>\n      <td>0.632812</td>\n      <td>0.483932</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.000700</td>\n      <td>0.437500</td>\n      <td>0.480024</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.081483</td>\n      <td>0.437500</td>\n      <td>0.498028</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.000500</td>\n      <td>0.476562</td>\n      <td>0.409507</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.059357</td>\n      <td>0.476562</td>\n      <td>0.501413</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.000700</td>\n      <td>0.484375</td>\n      <td>0.439500</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.087805</td>\n      <td>0.484375</td>\n      <td>0.501719</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.000700</td>\n      <td>0.367188</td>\n      <td>0.334564</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.083228</td>\n      <td>0.367188</td>\n      <td>0.483932</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.000600</td>\n      <td>0.500000</td>\n      <td>0.382173</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.078390</td>\n      <td>0.500000</td>\n      <td>0.501965</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.000900</td>\n      <td>0.437500</td>\n      <td>0.467653</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.115467</td>\n      <td>0.437500</td>\n      <td>0.498028</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.001300</td>\n      <td>0.335938</td>\n      <td>0.392947</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.160681</td>\n      <td>0.335938</td>\n      <td>0.474173</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.001100</td>\n      <td>0.515625</td>\n      <td>0.301680</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.132106</td>\n      <td>0.515625</td>\n      <td>0.501719</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.001300</td>\n      <td>0.453125</td>\n      <td>0.472908</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.158144</td>\n      <td>0.453125</td>\n      <td>0.499754</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.001300</td>\n      <td>0.429688</td>\n      <td>0.255664</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.165921</td>\n      <td>0.429688</td>\n      <td>0.496977</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.001600</td>\n      <td>0.523438</td>\n      <td>0.420581</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.198029</td>\n      <td>0.523438</td>\n      <td>0.501413</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.001700</td>\n      <td>0.484375</td>\n      <td>0.406092</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.218186</td>\n      <td>0.484375</td>\n      <td>0.501719</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.001900</td>\n      <td>0.437500</td>\n      <td>0.362435</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.233253</td>\n      <td>0.437500</td>\n      <td>0.498028</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.001500</td>\n      <td>0.250000</td>\n      <td>0.373741</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.184021</td>\n      <td>0.250000</td>\n      <td>0.434714</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.001500</td>\n      <td>0.492188</td>\n      <td>0.437374</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.184035</td>\n      <td>0.492188</td>\n      <td>0.501903</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.001900</td>\n      <td>0.546875</td>\n      <td>0.472371</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.231866</td>\n      <td>0.546875</td>\n      <td>0.499754</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.002000</td>\n      <td>0.554688</td>\n      <td>0.407153</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.251133</td>\n      <td>0.554688</td>\n      <td>0.498953</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.001800</td>\n      <td>0.453125</td>\n      <td>0.383990</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.229276</td>\n      <td>0.453125</td>\n      <td>0.499754</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.001600</td>\n      <td>0.546875</td>\n      <td>0.442920</td>\n      <td>2.289062</td>\n      <td>2.000000</td>\n      <td>39.000000</td>\n      <td>0.000000</td>\n      <td>2.289062</td>\n      <td>2.000000</td>\n      <td>39.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.194609</td>\n      <td>0.546875</td>\n      <td>0.499754</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.002500</td>\n      <td>0.656250</td>\n      <td>0.404257</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.315956</td>\n      <td>0.656250</td>\n      <td>0.476825</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.002500</td>\n      <td>0.671875</td>\n      <td>0.380338</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.311578</td>\n      <td>0.671875</td>\n      <td>0.471376</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.002400</td>\n      <td>0.468750</td>\n      <td>0.416861</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.298153</td>\n      <td>0.468750</td>\n      <td>0.500983</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.002300</td>\n      <td>0.679688</td>\n      <td>0.339040</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.287684</td>\n      <td>0.679688</td>\n      <td>0.468430</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.002700</td>\n      <td>0.554688</td>\n      <td>0.440561</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.335169</td>\n      <td>0.554688</td>\n      <td>0.498953</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.003000</td>\n      <td>0.523438</td>\n      <td>0.442915</td>\n      <td>2.132812</td>\n      <td>2.000000</td>\n      <td>19.000000</td>\n      <td>0.000000</td>\n      <td>2.132812</td>\n      <td>2.000000</td>\n      <td>19.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.377139</td>\n      <td>0.523438</td>\n      <td>0.501413</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.003000</td>\n      <td>0.390625</td>\n      <td>0.385056</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.372258</td>\n      <td>0.390625</td>\n      <td>0.489808</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.003100</td>\n      <td>0.656250</td>\n      <td>0.422420</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.392210</td>\n      <td>0.656250</td>\n      <td>0.476825</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.003900</td>\n      <td>0.445312</td>\n      <td>0.461884</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.486776</td>\n      <td>0.445312</td>\n      <td>0.498953</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.005900</td>\n      <td>0.453125</td>\n      <td>0.278298</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.733066</td>\n      <td>0.453125</td>\n      <td>0.499754</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.004300</td>\n      <td>0.625000</td>\n      <td>0.369794</td>\n      <td>2.210938</td>\n      <td>2.000000</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n      <td>2.210938</td>\n      <td>2.000000</td>\n      <td>29.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.532275</td>\n      <td>0.625000</td>\n      <td>0.486025</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.004800</td>\n      <td>0.710938</td>\n      <td>0.344814</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.603157</td>\n      <td>0.710938</td>\n      <td>0.455108</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.005500</td>\n      <td>0.539062</td>\n      <td>0.253542</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.682044</td>\n      <td>0.539062</td>\n      <td>0.500430</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.004700</td>\n      <td>0.539062</td>\n      <td>0.283540</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.585844</td>\n      <td>0.539062</td>\n      <td>0.500430</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.003600</td>\n      <td>0.484375</td>\n      <td>0.255669</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.453982</td>\n      <td>0.484375</td>\n      <td>0.501719</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.005300</td>\n      <td>0.398438</td>\n      <td>0.251725</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.656863</td>\n      <td>0.398438</td>\n      <td>0.491500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.006100</td>\n      <td>0.632812</td>\n      <td>0.295382</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.767022</td>\n      <td>0.632812</td>\n      <td>0.483932</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.005800</td>\n      <td>0.437500</td>\n      <td>0.244890</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.719110</td>\n      <td>0.437500</td>\n      <td>0.498028</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.006200</td>\n      <td>0.781250</td>\n      <td>0.182014</td>\n      <td>2.507812</td>\n      <td>2.000000</td>\n      <td>67.000000</td>\n      <td>0.000000</td>\n      <td>2.507812</td>\n      <td>2.000000</td>\n      <td>67.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.773751</td>\n      <td>0.781250</td>\n      <td>0.415023</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.005700</td>\n      <td>0.695312</td>\n      <td>0.364552</td>\n      <td>2.437500</td>\n      <td>2.000000</td>\n      <td>58.000000</td>\n      <td>0.000000</td>\n      <td>2.437500</td>\n      <td>2.000000</td>\n      <td>58.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.710177</td>\n      <td>0.695312</td>\n      <td>0.462084</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.005700</td>\n      <td>0.531250</td>\n      <td>0.263036</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.717044</td>\n      <td>0.531250</td>\n      <td>0.500983</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.006500</td>\n      <td>0.554688</td>\n      <td>0.320358</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.809310</td>\n      <td>0.554688</td>\n      <td>0.498953</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.007000</td>\n      <td>0.648438</td>\n      <td>0.313528</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>0.868870</td>\n      <td>0.648438</td>\n      <td>0.479334</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.008800</td>\n      <td>0.351562</td>\n      <td>0.328790</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>1.103494</td>\n      <td>0.351562</td>\n      <td>0.479334</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.008000</td>\n      <td>0.789062</td>\n      <td>0.285133</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>1.004817</td>\n      <td>0.789062</td>\n      <td>0.409577</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1638754103.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2329\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n","\u001b[0;32m/kaggle/working/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   2507\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2509\u001b[0;31m                 loss, completion_length, mean_kl = grpo_accumulated_loss(\n\u001b[0m\u001b[1;32m   2510\u001b[0m                     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m                     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36mgrpo_accumulated_loss\u001b[0;34m(trainer, input_ids, attention_mask, logits_to_keep, completion_mask, advantages, old_hidden_states, n_chunks, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m             ).logits\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         new_hidden_states = trainer.model(\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mPeftModel_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         )\n\u001b[1;32m   1338\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m         return self.base_model(\n\u001b[0m\u001b[1;32m   1340\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m             \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_no_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m             outputs = self.model(\n\u001b[0m\u001b[1;32m   1151\u001b[0m                 \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                 \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    963\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0mcausal_mask\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_callback_from_stance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m\"use_reentrant=False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         gen = _checkpoint_without_reentrant_generator(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth_zoo/gradient_checkpointing.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_gpu_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMAIN_STREAM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXTRA_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaDecoderLayer_fast_forward\u001b[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_rms_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mhidden_states\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0mcausal_mask\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaAttention_fast_forward\u001b[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;31m#     else inplace_rope_embedding(Q, K, cos, sin, position_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_rope_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_callback_from_stance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/rope_embedding.py\u001b[0m in \u001b[0;36mfast_rope_embedding\u001b[0;34m(Q, K, cos, sin)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFast_RoPE_Embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# synchronize before cat to avoid race condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mtorch_device_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/streams.py\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m            \u001b[0;31m`\u001b[0m\u001b[0mCUDA\u001b[0m \u001b[0mStream\u001b[0m \u001b[0mdocumentation\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"trainer.state.log_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T22:02:39.582780Z","iopub.execute_input":"2025-09-15T22:02:39.583054Z","iopub.status.idle":"2025-09-15T22:02:39.599669Z","shell.execute_reply.started":"2025-09-15T22:02:39.583032Z","shell.execute_reply":"2025-09-15T22:02:39.598933Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[{'loss': 0.0004,\n  'grad_norm': nan,\n  'learning_rate': 0.0,\n  'num_tokens': 23808.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3203125,\n  'rewards/grpo_reward_func/std': 0.4684300124645233,\n  'reward': 0.3203125,\n  'reward_std': 0.36743485927581787,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.051833580480888486,\n  'epoch': 0.013333333333333334,\n  'step': 1},\n {'loss': 0.0006,\n  'grad_norm': nan,\n  'learning_rate': 0.0,\n  'num_tokens': 46992.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4140625,\n  'rewards/grpo_reward_func/std': 0.49449479579925537,\n  'reward': 0.4140625,\n  'reward_std': 0.3826971650123596,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.07390407146885991,\n  'epoch': 0.02666666666666667,\n  'step': 2},\n {'loss': 0.0005,\n  'grad_norm': nan,\n  'learning_rate': 0.0,\n  'num_tokens': 70080.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.375,\n  'rewards/grpo_reward_func/std': 0.4860251843929291,\n  'reward': 0.375,\n  'reward_std': 0.39400771260261536,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.0659835641272366,\n  'epoch': 0.04,\n  'step': 3},\n {'loss': 0.0005,\n  'grad_norm': 9.201554298400879,\n  'learning_rate': 0.0,\n  'num_tokens': 92576.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.34375,\n  'rewards/grpo_reward_func/std': 0.47682511806488037,\n  'reward': 0.34375,\n  'reward_std': 0.3061561584472656,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.05805521411821246,\n  'epoch': 0.05333333333333334,\n  'step': 4},\n {'loss': 0.0005,\n  'grad_norm': 14.536378860473633,\n  'learning_rate': 1.0000000000000002e-06,\n  'num_tokens': 114800.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.421875,\n  'rewards/grpo_reward_func/std': 0.4957992732524872,\n  'reward': 0.421875,\n  'reward_std': 0.2977414131164551,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.057816967368125916,\n  'epoch': 0.06666666666666667,\n  'step': 5},\n {'loss': 0.0005,\n  'grad_norm': 24.003135681152344,\n  'learning_rate': 2.0000000000000003e-06,\n  'num_tokens': 137488.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5234375,\n  'rewards/grpo_reward_func/std': 0.5014128684997559,\n  'reward': 0.5234375,\n  'reward_std': 0.37822139263153076,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.06060383282601833,\n  'epoch': 0.08,\n  'step': 6},\n {'loss': 0.0005,\n  'grad_norm': 24.50774574279785,\n  'learning_rate': 3e-06,\n  'num_tokens': 159344.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3671875,\n  'rewards/grpo_reward_func/std': 0.4839322865009308,\n  'reward': 0.3671875,\n  'reward_std': 0.42476963996887207,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.06732053635641932,\n  'epoch': 0.09333333333333334,\n  'step': 7},\n {'loss': 0.0004,\n  'grad_norm': 6.2402544021606445,\n  'learning_rate': 4.000000000000001e-06,\n  'num_tokens': 181856.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4765625,\n  'rewards/grpo_reward_func/std': 0.5014128684997559,\n  'reward': 0.4765625,\n  'reward_std': 0.3527093529701233,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.046924403170123696,\n  'epoch': 0.10666666666666667,\n  'step': 8},\n {'loss': 0.0006,\n  'grad_norm': 8.222119331359863,\n  'learning_rate': 5e-06,\n  'num_tokens': 203392.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4375,\n  'rewards/grpo_reward_func/std': 0.49802759289741516,\n  'reward': 0.4375,\n  'reward_std': 0.24489018321037292,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.06979854218661785,\n  'epoch': 0.12,\n  'step': 9},\n {'loss': 0.0006,\n  'grad_norm': 13.30237102508545,\n  'learning_rate': 6e-06,\n  'num_tokens': 226256.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.7109375,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.7109375,\n  'reward_std': 0.36531317234039307,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.0727632932830602,\n  'epoch': 0.13333333333333333,\n  'step': 10},\n {'loss': 0.0005,\n  'grad_norm': 12.305510520935059,\n  'learning_rate': 7e-06,\n  'num_tokens': 249632.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4609375,\n  'rewards/grpo_reward_func/std': 0.5004304051399231,\n  'reward': 0.4609375,\n  'reward_std': 0.5012978911399841,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.05890945834107697,\n  'epoch': 0.14666666666666667,\n  'step': 11},\n {'loss': 0.0005,\n  'grad_norm': 11.136165618896484,\n  'learning_rate': 8.000000000000001e-06,\n  'num_tokens': 271728.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.28125,\n  'rewards/grpo_reward_func/std': 0.4513758420944214,\n  'reward': 0.28125,\n  'reward_std': 0.33008331060409546,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.06192751321941614,\n  'epoch': 0.16,\n  'step': 12},\n {'loss': 0.0005,\n  'grad_norm': 9.498358726501465,\n  'learning_rate': 9e-06,\n  'num_tokens': 295217.0,\n  'completions/mean_length': 3.8828125,\n  'completions/min_length': 2.0,\n  'completions/max_length': 243.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 3.8828125,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 243.0,\n  'rewards/grpo_reward_func/mean': 0.2578125,\n  'rewards/grpo_reward_func/std': 0.43914902210235596,\n  'reward': 0.2578125,\n  'reward_std': 0.36007601022720337,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 3.8828125,\n  'kl': 0.057484790682792664,\n  'epoch': 0.17333333333333334,\n  'step': 13},\n {'loss': 0.0006,\n  'grad_norm': 5.973301410675049,\n  'learning_rate': 1e-05,\n  'num_tokens': 318673.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.6328125,\n  'rewards/grpo_reward_func/std': 0.4839322865009308,\n  'reward': 0.6328125,\n  'reward_std': 0.40769004821777344,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.08027689205482602,\n  'epoch': 0.18666666666666668,\n  'step': 14},\n {'loss': 0.0007,\n  'grad_norm': 14.785747528076172,\n  'learning_rate': 9.947368421052632e-06,\n  'num_tokens': 340945.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4375,\n  'rewards/grpo_reward_func/std': 0.49802759289741516,\n  'reward': 0.4375,\n  'reward_std': 0.4800243079662323,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.08148269820958376,\n  'epoch': 0.2,\n  'step': 15},\n {'loss': 0.0005,\n  'grad_norm': 13.624408721923828,\n  'learning_rate': 9.894736842105264e-06,\n  'num_tokens': 364369.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4765625,\n  'rewards/grpo_reward_func/std': 0.5014128684997559,\n  'reward': 0.4765625,\n  'reward_std': 0.4095073640346527,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.059357081074267626,\n  'epoch': 0.21333333333333335,\n  'step': 16},\n {'loss': 0.0007,\n  'grad_norm': 13.511259078979492,\n  'learning_rate': 9.842105263157896e-06,\n  'num_tokens': 387057.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.484375,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.484375,\n  'reward_std': 0.4395000636577606,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.0878047738224268,\n  'epoch': 0.22666666666666666,\n  'step': 17},\n {'loss': 0.0007,\n  'grad_norm': 6.8357367515563965,\n  'learning_rate': 9.789473684210527e-06,\n  'num_tokens': 410081.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3671875,\n  'rewards/grpo_reward_func/std': 0.4839322865009308,\n  'reward': 0.3671875,\n  'reward_std': 0.3345639705657959,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.08322791988030076,\n  'epoch': 0.24,\n  'step': 18},\n {'loss': 0.0006,\n  'grad_norm': 8.562047958374023,\n  'learning_rate': 9.736842105263159e-06,\n  'num_tokens': 431857.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5,\n  'rewards/grpo_reward_func/std': 0.5019646286964417,\n  'reward': 0.5,\n  'reward_std': 0.382173091173172,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.0783900460228324,\n  'epoch': 0.25333333333333335,\n  'step': 19},\n {'loss': 0.0009,\n  'grad_norm': 14.33238697052002,\n  'learning_rate': 9.68421052631579e-06,\n  'num_tokens': 454401.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4375,\n  'rewards/grpo_reward_func/std': 0.49802759289741516,\n  'reward': 0.4375,\n  'reward_std': 0.46765291690826416,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.11546656582504511,\n  'epoch': 0.26666666666666666,\n  'step': 20},\n {'loss': 0.0013,\n  'grad_norm': 13.25973892211914,\n  'learning_rate': 9.631578947368422e-06,\n  'num_tokens': 477201.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3359375,\n  'rewards/grpo_reward_func/std': 0.47417303919792175,\n  'reward': 0.3359375,\n  'reward_std': 0.39294689893722534,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.1606813408434391,\n  'epoch': 0.28,\n  'step': 21},\n {'loss': 0.0011,\n  'grad_norm': 12.507466316223145,\n  'learning_rate': 9.578947368421054e-06,\n  'num_tokens': 500049.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.515625,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.515625,\n  'reward_std': 0.30168038606643677,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.13210575468838215,\n  'epoch': 0.29333333333333333,\n  'step': 22},\n {'loss': 0.0013,\n  'grad_norm': 16.519142150878906,\n  'learning_rate': 9.526315789473684e-06,\n  'num_tokens': 522337.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.4729077219963074,\n  'frac_reward_zero_std': 0.0,\n  'completion_length': 2.0,\n  'kl': 0.1581442141905427,\n  'epoch': 0.30666666666666664,\n  'step': 23},\n {'loss': 0.0013,\n  'grad_norm': 14.219734191894531,\n  'learning_rate': 9.473684210526315e-06,\n  'num_tokens': 545121.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4296875,\n  'rewards/grpo_reward_func/std': 0.4969765841960907,\n  'reward': 0.4296875,\n  'reward_std': 0.25566399097442627,\n  'frac_reward_zero_std': 0.4375,\n  'completion_length': 2.0,\n  'kl': 0.165920939296484,\n  'epoch': 0.32,\n  'step': 24},\n {'loss': 0.0016,\n  'grad_norm': 13.189663887023926,\n  'learning_rate': 9.421052631578949e-06,\n  'num_tokens': 568001.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5234375,\n  'rewards/grpo_reward_func/std': 0.5014128684997559,\n  'reward': 0.5234375,\n  'reward_std': 0.42058056592941284,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.19802852347493172,\n  'epoch': 0.3333333333333333,\n  'step': 25},\n {'loss': 0.0017,\n  'grad_norm': 16.401966094970703,\n  'learning_rate': 9.36842105263158e-06,\n  'num_tokens': 591457.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.484375,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.484375,\n  'reward_std': 0.40609240531921387,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.21818599104881287,\n  'epoch': 0.3466666666666667,\n  'step': 26},\n {'loss': 0.0019,\n  'grad_norm': 8.193816184997559,\n  'learning_rate': 9.315789473684212e-06,\n  'num_tokens': 614305.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4375,\n  'rewards/grpo_reward_func/std': 0.49802759289741516,\n  'reward': 0.4375,\n  'reward_std': 0.3624350428581238,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.23325288202613592,\n  'epoch': 0.36,\n  'step': 27},\n {'loss': 0.0015,\n  'grad_norm': 10.030628204345703,\n  'learning_rate': 9.263157894736842e-06,\n  'num_tokens': 638545.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.25,\n  'rewards/grpo_reward_func/std': 0.434714138507843,\n  'reward': 0.25,\n  'reward_std': 0.37374070286750793,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.18402085453271866,\n  'epoch': 0.37333333333333335,\n  'step': 28},\n {'loss': 0.0015,\n  'grad_norm': 17.394821166992188,\n  'learning_rate': 9.210526315789474e-06,\n  'num_tokens': 661937.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4921875,\n  'rewards/grpo_reward_func/std': 0.5019033551216125,\n  'reward': 0.4921875,\n  'reward_std': 0.4373735189437866,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.1840351428836584,\n  'epoch': 0.38666666666666666,\n  'step': 29},\n {'loss': 0.0019,\n  'grad_norm': 18.21917724609375,\n  'learning_rate': 9.157894736842105e-06,\n  'num_tokens': 684033.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.546875,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.546875,\n  'reward_std': 0.4723709225654602,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.23186593875288963,\n  'epoch': 0.4,\n  'step': 30},\n {'loss': 0.002,\n  'grad_norm': 25.579076766967773,\n  'learning_rate': 9.105263157894739e-06,\n  'num_tokens': 707841.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5546875,\n  'rewards/grpo_reward_func/std': 0.4989531338214874,\n  'reward': 0.5546875,\n  'reward_std': 0.40715324878692627,\n  'frac_reward_zero_std': 0.125,\n  'completion_length': 2.0,\n  'kl': 0.25113274343311787,\n  'epoch': 0.41333333333333333,\n  'step': 31},\n {'loss': 0.0018,\n  'grad_norm': 13.55858039855957,\n  'learning_rate': 9.05263157894737e-06,\n  'num_tokens': 731233.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.38399040699005127,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.22927634418010712,\n  'epoch': 0.4266666666666667,\n  'step': 32},\n {'loss': 0.0016,\n  'grad_norm': 17.263477325439453,\n  'learning_rate': 9e-06,\n  'num_tokens': 754486.0,\n  'completions/mean_length': 2.2890625,\n  'completions/min_length': 2.0,\n  'completions/max_length': 39.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.2890625,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 39.0,\n  'rewards/grpo_reward_func/mean': 0.546875,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.546875,\n  'reward_std': 0.44291990995407104,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.2890625,\n  'kl': 0.19460853934288025,\n  'epoch': 0.44,\n  'step': 33},\n {'loss': 0.0025,\n  'grad_norm': 28.697141647338867,\n  'learning_rate': 8.947368421052632e-06,\n  'num_tokens': 776726.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.65625,\n  'rewards/grpo_reward_func/std': 0.47682511806488037,\n  'reward': 0.65625,\n  'reward_std': 0.4042574465274811,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.3159564137458801,\n  'epoch': 0.4533333333333333,\n  'step': 34},\n {'loss': 0.0025,\n  'grad_norm': 36.98267364501953,\n  'learning_rate': 8.894736842105264e-06,\n  'num_tokens': 799206.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.671875,\n  'rewards/grpo_reward_func/std': 0.4713755249977112,\n  'reward': 0.671875,\n  'reward_std': 0.3803381323814392,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.31157764606177807,\n  'epoch': 0.4666666666666667,\n  'step': 35},\n {'loss': 0.0024,\n  'grad_norm': 21.59844398498535,\n  'learning_rate': 8.842105263157895e-06,\n  'num_tokens': 822630.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.46875,\n  'rewards/grpo_reward_func/std': 0.5009832978248596,\n  'reward': 0.46875,\n  'reward_std': 0.41686129570007324,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.29815326631069183,\n  'epoch': 0.48,\n  'step': 36},\n {'loss': 0.0023,\n  'grad_norm': 14.440157890319824,\n  'learning_rate': 8.789473684210527e-06,\n  'num_tokens': 845862.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.6796875,\n  'rewards/grpo_reward_func/std': 0.4684300124645233,\n  'reward': 0.6796875,\n  'reward_std': 0.33903974294662476,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.28768437914550304,\n  'epoch': 0.49333333333333335,\n  'step': 37},\n {'loss': 0.0027,\n  'grad_norm': 25.20121192932129,\n  'learning_rate': 8.736842105263158e-06,\n  'num_tokens': 869094.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5546875,\n  'rewards/grpo_reward_func/std': 0.4989531338214874,\n  'reward': 0.5546875,\n  'reward_std': 0.440560907125473,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.33516863733530045,\n  'epoch': 0.5066666666666667,\n  'step': 38},\n {'loss': 0.003,\n  'grad_norm': 20.710899353027344,\n  'learning_rate': 8.68421052631579e-06,\n  'num_tokens': 891815.0,\n  'completions/mean_length': 2.1328125,\n  'completions/min_length': 2.0,\n  'completions/max_length': 19.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.1328125,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 19.0,\n  'rewards/grpo_reward_func/mean': 0.5234375,\n  'rewards/grpo_reward_func/std': 0.5014128684997559,\n  'reward': 0.5234375,\n  'reward_std': 0.44291502237319946,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.1328125,\n  'kl': 0.3771388418972492,\n  'epoch': 0.52,\n  'step': 39},\n {'loss': 0.003,\n  'grad_norm': 25.316692352294922,\n  'learning_rate': 8.631578947368422e-06,\n  'num_tokens': 914695.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.390625,\n  'rewards/grpo_reward_func/std': 0.4898075461387634,\n  'reward': 0.390625,\n  'reward_std': 0.38505613803863525,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.0,\n  'kl': 0.37225847505033016,\n  'epoch': 0.5333333333333333,\n  'step': 40},\n {'loss': 0.0031,\n  'grad_norm': 11.720211029052734,\n  'learning_rate': 8.578947368421053e-06,\n  'num_tokens': 937239.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.65625,\n  'rewards/grpo_reward_func/std': 0.47682511806488037,\n  'reward': 0.65625,\n  'reward_std': 0.422420471906662,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.3922099396586418,\n  'epoch': 0.5466666666666666,\n  'step': 41},\n {'loss': 0.0039,\n  'grad_norm': 8.816999435424805,\n  'learning_rate': 8.526315789473685e-06,\n  'num_tokens': 959863.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4453125,\n  'rewards/grpo_reward_func/std': 0.4989531338214874,\n  'reward': 0.4453125,\n  'reward_std': 0.4618838429450989,\n  'frac_reward_zero_std': 0.0625,\n  'completion_length': 2.0,\n  'kl': 0.48677585273981094,\n  'epoch': 0.56,\n  'step': 42},\n {'loss': 0.0059,\n  'grad_norm': 7.789158821105957,\n  'learning_rate': 8.473684210526317e-06,\n  'num_tokens': 982519.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.453125,\n  'rewards/grpo_reward_func/std': 0.4997538626194,\n  'reward': 0.453125,\n  'reward_std': 0.2782978415489197,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.7330662608146667,\n  'epoch': 0.5733333333333334,\n  'step': 43},\n {'loss': 0.0043,\n  'grad_norm': 21.16299057006836,\n  'learning_rate': 8.421052631578948e-06,\n  'num_tokens': 1005954.0,\n  'completions/mean_length': 2.2109375,\n  'completions/min_length': 2.0,\n  'completions/max_length': 29.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.2109375,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 29.0,\n  'rewards/grpo_reward_func/mean': 0.625,\n  'rewards/grpo_reward_func/std': 0.4860251843929291,\n  'reward': 0.625,\n  'reward_std': 0.3697938919067383,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.2109375,\n  'kl': 0.5322754830121994,\n  'epoch': 0.5866666666666667,\n  'step': 44},\n {'loss': 0.0048,\n  'grad_norm': 12.619955062866211,\n  'learning_rate': 8.36842105263158e-06,\n  'num_tokens': 1027682.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.7109375,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.7109375,\n  'reward_std': 0.3448137044906616,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 0.603157214820385,\n  'epoch': 0.6,\n  'step': 45},\n {'loss': 0.0055,\n  'grad_norm': 23.727487564086914,\n  'learning_rate': 8.315789473684212e-06,\n  'num_tokens': 1051298.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5390625,\n  'rewards/grpo_reward_func/std': 0.5004304051399231,\n  'reward': 0.5390625,\n  'reward_std': 0.25354230403900146,\n  'frac_reward_zero_std': 0.4375,\n  'completion_length': 2.0,\n  'kl': 0.6820435971021652,\n  'epoch': 0.6133333333333333,\n  'step': 46},\n {'loss': 0.0047,\n  'grad_norm': 9.443785667419434,\n  'learning_rate': 8.263157894736843e-06,\n  'num_tokens': 1074802.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5390625,\n  'rewards/grpo_reward_func/std': 0.5004304051399231,\n  'reward': 0.5390625,\n  'reward_std': 0.28353992104530334,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.5858440361917019,\n  'epoch': 0.6266666666666667,\n  'step': 47},\n {'loss': 0.0036,\n  'grad_norm': 5.6902923583984375,\n  'learning_rate': 8.210526315789475e-06,\n  'num_tokens': 1097714.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.484375,\n  'rewards/grpo_reward_func/std': 0.5017194747924805,\n  'reward': 0.484375,\n  'reward_std': 0.25566887855529785,\n  'frac_reward_zero_std': 0.4375,\n  'completion_length': 2.0,\n  'kl': 0.45398229360580444,\n  'epoch': 0.64,\n  'step': 48},\n {'loss': 0.0053,\n  'grad_norm': 9.554630279541016,\n  'learning_rate': 8.157894736842106e-06,\n  'num_tokens': 1121794.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3984375,\n  'rewards/grpo_reward_func/std': 0.4915000796318054,\n  'reward': 0.3984375,\n  'reward_std': 0.2517249882221222,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.6568633019924164,\n  'epoch': 0.6533333333333333,\n  'step': 49},\n {'loss': 0.0061,\n  'grad_norm': 13.545095443725586,\n  'learning_rate': 8.105263157894736e-06,\n  'num_tokens': 1144770.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.6328125,\n  'rewards/grpo_reward_func/std': 0.4839322865009308,\n  'reward': 0.6328125,\n  'reward_std': 0.29538238048553467,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.7670221067965031,\n  'epoch': 0.6666666666666666,\n  'step': 50},\n {'loss': 0.0058,\n  'grad_norm': 16.006380081176758,\n  'learning_rate': 8.052631578947368e-06,\n  'num_tokens': 1167330.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.4375,\n  'rewards/grpo_reward_func/std': 0.49802759289741516,\n  'reward': 0.4375,\n  'reward_std': 0.24489018321037292,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.7191101238131523,\n  'epoch': 0.68,\n  'step': 51},\n {'loss': 0.0062,\n  'grad_norm': 16.27107048034668,\n  'learning_rate': 8.000000000000001e-06,\n  'num_tokens': 1191107.0,\n  'completions/mean_length': 2.5078125,\n  'completions/min_length': 2.0,\n  'completions/max_length': 67.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.5078125,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 67.0,\n  'rewards/grpo_reward_func/mean': 0.78125,\n  'rewards/grpo_reward_func/std': 0.41502299904823303,\n  'reward': 0.78125,\n  'reward_std': 0.1820138692855835,\n  'frac_reward_zero_std': 0.5625,\n  'completion_length': 2.5078125,\n  'kl': 0.7737511917948723,\n  'epoch': 0.6933333333333334,\n  'step': 52},\n {'loss': 0.0057,\n  'grad_norm': 14.332353591918945,\n  'learning_rate': 7.947368421052633e-06,\n  'num_tokens': 1213659.0,\n  'completions/mean_length': 2.4375,\n  'completions/min_length': 2.0,\n  'completions/max_length': 58.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.4375,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 58.0,\n  'rewards/grpo_reward_func/mean': 0.6953125,\n  'rewards/grpo_reward_func/std': 0.46208351850509644,\n  'reward': 0.6953125,\n  'reward_std': 0.3645517826080322,\n  'frac_reward_zero_std': 0.1875,\n  'completion_length': 2.4375,\n  'kl': 0.7101766988635063,\n  'epoch': 0.7066666666666667,\n  'step': 53},\n {'loss': 0.0057,\n  'grad_norm': 24.567920684814453,\n  'learning_rate': 7.894736842105265e-06,\n  'num_tokens': 1238187.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.53125,\n  'rewards/grpo_reward_func/std': 0.5009832978248596,\n  'reward': 0.53125,\n  'reward_std': 0.2630355656147003,\n  'frac_reward_zero_std': 0.375,\n  'completion_length': 2.0,\n  'kl': 0.7170438915491104,\n  'epoch': 0.72,\n  'step': 54},\n {'loss': 0.0065,\n  'grad_norm': 28.73575210571289,\n  'learning_rate': 7.842105263157895e-06,\n  'num_tokens': 1261227.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.5546875,\n  'rewards/grpo_reward_func/std': 0.4989531338214874,\n  'reward': 0.5546875,\n  'reward_std': 0.32035762071609497,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.8093104958534241,\n  'epoch': 0.7333333333333333,\n  'step': 55},\n {'loss': 0.007,\n  'grad_norm': 32.74520492553711,\n  'learning_rate': 7.789473684210526e-06,\n  'num_tokens': 1284219.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.6484375,\n  'rewards/grpo_reward_func/std': 0.4793342351913452,\n  'reward': 0.6484375,\n  'reward_std': 0.3135277032852173,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 0.8688697218894958,\n  'epoch': 0.7466666666666667,\n  'step': 56},\n {'loss': 0.0088,\n  'grad_norm': 9.421342849731445,\n  'learning_rate': 7.736842105263158e-06,\n  'num_tokens': 1307803.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.3515625,\n  'rewards/grpo_reward_func/std': 0.4793342351913452,\n  'reward': 0.3515625,\n  'reward_std': 0.32879000902175903,\n  'frac_reward_zero_std': 0.25,\n  'completion_length': 2.0,\n  'kl': 1.1034942120313644,\n  'epoch': 0.76,\n  'step': 57},\n {'loss': 0.008,\n  'grad_norm': nan,\n  'learning_rate': 7.68421052631579e-06,\n  'num_tokens': 1330523.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.7890625,\n  'rewards/grpo_reward_func/std': 0.4095771610736847,\n  'reward': 0.7890625,\n  'reward_std': 0.28513264656066895,\n  'frac_reward_zero_std': 0.3125,\n  'completion_length': 2.0,\n  'kl': 1.00481715798378,\n  'epoch': 0.7733333333333333,\n  'step': 58},\n {'loss': 0.0051,\n  'grad_norm': 9.51930046081543,\n  'learning_rate': 7.68421052631579e-06,\n  'num_tokens': 1354059.0,\n  'completions/mean_length': 2.0,\n  'completions/min_length': 2.0,\n  'completions/max_length': 2.0,\n  'completions/clipped_ratio': 0.0,\n  'completions/mean_terminated_length': 2.0,\n  'completions/min_terminated_length': 2.0,\n  'completions/max_terminated_length': 2.0,\n  'rewards/grpo_reward_func/mean': 0.7109375,\n  'rewards/grpo_reward_func/std': 0.45510825514793396,\n  'reward': 0.7109375,\n  'reward_std': 0.1804162561893463,\n  'frac_reward_zero_std': 0.625,\n  'completion_length': 2.0,\n  'kl': 0.6390331760048866,\n  'epoch': 0.7866666666666666,\n  'step': 59}]"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"trained_model = trainer.model\ntrained_tokenizer = trainer.tokenizer","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nm-a94SQDjSi","outputId":"b0e9f21a-9bf1-4e5f-ab69-7367fe41e7f5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from point_set_verifier import PointSetVerifier\nfrom tqdm import tqdm\nfrom data import Data\n\ndef evaluate_model(model, tokenizer, test_datasets, game):\n    results = {}\n    verifier = PointSetVerifier()\n\n    model.eval()\n    device = model.device\n\n    for difficulty, dataset in tqdm(test_datasets.items()):\n        correct = 0\n        total = len(dataset)\n\n        for item in dataset:\n            prompt = format_prompt(item[\"question\"])\n\n            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n\n            with torch.no_grad():\n                outputs = model.generate(\n                    **inputs,\n                    max_new_tokens=100,\n                    do_sample=True,\n                )\n\n            prediction = tokenizer.decode(outputs[0].cpu(), skip_special_tokens=True)\n            prediction = prediction.split(\"assistant\")[-1].strip()\n            print(PointSetVerifier().extract_answer(test_solution=prediction))\n            print('-' * 100)\n            print(item['answer'])\n\n            data = Data(\n                question=item['question'],\n                answer=item['answer'],\n                difficulty=item['difficulty'],\n                metadata=item['metadata']\n            )\n\n            is_correct = verifier.verify(data, prediction)\n            if is_correct:\n                correct += 1\n\n        accuracy = correct / total\n        results[difficulty] = accuracy\n        print(f\"Difficulty {difficulty}: Accuracy = {accuracy:.3f}\")\n\n    return results","metadata":{"id":"L8K4W_nbGnIU"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default_model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"Qwen/Qwen2.5-3B-Instruct\",\n    max_seq_length = 1024,\n    dtype = None,\n    load_in_4bit = True,\n)\nprint(\"Evaluating trained model...\")\ntrained_results = evaluate_model(default_model, tokenizer, test_datasets, game)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OX30IQdYCrtB","outputId":"06964a33-883c-49b5-b0cc-2bb4615e4263","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.9.4: Fast Qwen2 patching. Transformers: 4.56.1.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Evaluating trained model...\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["external\n","----------------------------------------------------------------------------------------------------\n","external\n","internal\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","boundary\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","boundary\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","boundary\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","boundary\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","internal\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","internal\n","----------------------------------------------------------------------------------------------------\n","external\n","boundary\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","internal\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","internal\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","boundary\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","internal\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","internal\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n","internal\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","external\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","external\n","----------------------------------------------------------------------------------------------------\n","internal\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:21<00:00, 21.08s/it]"]},{"output_type":"stream","name":"stdout","text":["external\n","----------------------------------------------------------------------------------------------------\n","boundary\n","Difficulty difficulty_3: Accuracy = 0.270\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"RJzWEuWoGwc4"},"outputs":[],"execution_count":null}]}